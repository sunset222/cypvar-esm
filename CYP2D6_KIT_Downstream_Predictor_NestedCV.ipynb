{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f3308c-a9ca-4764-b209-946ddc6e66c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  6 09:23:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:65:00.0 Off |                  Off |\n",
      "| 74%   33C    P8             15W /  450W |   11853MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    On  |   00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   44C    P0             84W /  350W |   16319MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    162942      C   ...miniconda3/envs/deep_cyp/bin/python      11454MiB |\n",
      "|    0   N/A  N/A   2635381      C   ...miniconda3/envs/deep_cyp/bin/python        384MiB |\n",
      "|    1   N/A  N/A     89917      C   ...miniconda3/envs/deep_cyp/bin/python        798MiB |\n",
      "|    1   N/A  N/A    162942      C   ...miniconda3/envs/deep_cyp/bin/python      11528MiB |\n",
      "|    1   N/A  N/A    196997      C   ...miniconda3/envs/deep_cyp/bin/python        736MiB |\n",
      "|    1   N/A  N/A    619222      C   ...miniconda3/envs/deep_cyp/bin/python        872MiB |\n",
      "|    1   N/A  N/A    643722      C   ...miniconda3/envs/deep_cyp/bin/python        656MiB |\n",
      "|    1   N/A  N/A   3603275      C   ...miniconda3/envs/deep_cyp/bin/python        766MiB |\n",
      "|    1   N/A  N/A   4009804      C   ...miniconda3/envs/deep_cyp/bin/python        920MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "# deterministic 모드 활성화\n",
    "import os\n",
    "import torch\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3eec1-5c2d-44c2-b690-d7687f30688d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a235b45-fe07-4869-a071-cb56e8c773d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8075517-d4b1-425d-b7c9-4ef5d7ce3527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "with open(\"data/cyp2d6_nested_STCV_split_250727.pkl\", \"rb\") as f:\n",
    "    (train_df_list, test_df_list) = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d775cef-b1fe-449f-a5df-221d483cf295",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.912204945951418"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_list[0]['cl'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ec758b-cd0e-417a-a634-c4614184231f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/CYP2D6_MT_KIT_ESM3_250624.pkl\", \"rb\") as f:\n",
    "    allele_features = pickle.load(f)\n",
    "with open(\"data/MoleBERT_Substrate_NoPreMoleBERT_KIT_0624.pkl\", \"rb\") as f:\n",
    "    substrate_features = pickle.load(f)\n",
    "\n",
    "from src.utils.proj_dataset import MoleculeProteinDataset, MoleculeProteinCollate\n",
    "\n",
    "from src.proj_model import InteractionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fe52c3-a5e8-46fb-a25b-f28e6f92fb74",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "for key in substrate_features.keys():\n",
    "    mat = substrate_features[key]\n",
    "    global_emb = np.expand_dims(np.mean(mat, axis = 0), axis=0)\n",
    "    rev_mat = np.concatenate([global_emb, mat], axis = 0)\n",
    "    substrate_features[key] = rev_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84c37c2-c59b-4d5f-b0cf-6998a55e023e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*1': array([[ 1.0547069 , -1.4404287 ,  0.91990715, ..., -1.5899466 ,\n",
       "          1.9418132 , -1.5260013 ],\n",
       "        [ 0.11814488,  0.48241052,  0.21860471, ...,  1.1572773 ,\n",
       "          0.83054334, -0.839961  ],\n",
       "        [-0.42900905, -1.323586  ,  0.2802592 , ..., -1.0619283 ,\n",
       "         -0.2439166 ,  0.3374662 ],\n",
       "        ...,\n",
       "        [-0.31299707, -1.1495969 ,  0.19314715, ..., -1.0401504 ,\n",
       "         -0.38553315,  0.47721303],\n",
       "        [-0.1899054 , -1.2889016 ,  0.5255466 , ..., -1.2711152 ,\n",
       "         -0.0319083 ,  0.11407533],\n",
       "        [ 0.61902744, -0.60029346,  0.6328605 , ..., -0.09231935,\n",
       "          2.2781324 , -1.5122143 ]], dtype=float32),\n",
       " '*10': array([[ 0.90393835, -0.6548745 ,  0.57838243, ..., -0.33276322,\n",
       "          2.0565543 , -1.5532483 ],\n",
       "        [ 0.01089484,  0.68340033,  0.25083   , ...,  1.3242545 ,\n",
       "          0.50918025, -0.7407727 ],\n",
       "        [-0.14995731, -1.7649901 ,  0.7038571 , ..., -1.4677972 ,\n",
       "          0.37727422, -0.26608592],\n",
       "        ...,\n",
       "        [-0.31158498, -1.1498286 ,  0.20316271, ..., -1.0429035 ,\n",
       "         -0.38187814,  0.46586907],\n",
       "        [ 0.21264629, -1.535716  ,  0.9034802 , ..., -1.6576966 ,\n",
       "          0.62159055, -0.37424424],\n",
       "        [ 0.16551328,  0.18965402,  0.31343067, ...,  0.92685354,\n",
       "          1.4579779 , -1.0872989 ]], dtype=float32),\n",
       " '*14': array([[ 1.1278491e+00, -1.1719964e+00,  8.0850065e-01, ...,\n",
       "         -1.2651244e+00,  2.0394139e+00, -1.5830269e+00],\n",
       "        [ 5.2279435e-02,  5.6767911e-01,  1.9939084e-01, ...,\n",
       "          1.2468994e+00,  6.7475080e-01, -7.7124047e-01],\n",
       "        [-4.1963753e-01, -1.3994492e+00,  3.4748885e-01, ...,\n",
       "         -1.1061995e+00, -1.5691817e-01,  2.4535616e-01],\n",
       "        ...,\n",
       "        [-3.1435531e-01, -1.1521981e+00,  2.1072772e-01, ...,\n",
       "         -1.0416176e+00, -3.8504466e-01,  4.5683527e-01],\n",
       "        [ 1.8792119e-03, -1.4265057e+00,  7.2845209e-01, ...,\n",
       "         -1.4747365e+00,  2.9053119e-01, -1.3240263e-01],\n",
       "        [ 2.3775865e-01,  5.2627217e-02,  3.6532789e-01, ...,\n",
       "          7.7671266e-01,  1.6434354e+00, -1.1818885e+00]], dtype=float32),\n",
       " '*17': array([[ 1.1091391 , -1.2845639 ,  0.8585904 , ..., -1.4308715 ,\n",
       "          1.994306  , -1.5615387 ],\n",
       "        [ 0.06912319,  0.5454766 ,  0.20153466, ...,  1.2248647 ,\n",
       "          0.714591  , -0.7871508 ],\n",
       "        [-0.42866704, -1.3455555 ,  0.29975188, ..., -1.0727822 ,\n",
       "         -0.22058746,  0.3107336 ],\n",
       "        ...,\n",
       "        [-0.3118273 , -1.14993   ,  0.1964603 , ..., -1.0411882 ,\n",
       "         -0.3842495 ,  0.47335678],\n",
       "        [-0.12843616, -1.3366843 ,  0.597873  , ..., -1.3411587 ,\n",
       "          0.07534298,  0.02929002],\n",
       "        [ 0.47407773, -0.34245   ,  0.5292984 , ...,  0.2740344 ,\n",
       "          2.0836515 , -1.4088483 ]], dtype=float32),\n",
       " '*2': array([[ 1.1071975 , -1.2918503 ,  0.86178404, ..., -1.4394894 ,\n",
       "          1.9923546 , -1.5601186 ],\n",
       "        [ 0.0783712 ,  0.5339368 ,  0.20388739, ...,  1.2124938 ,\n",
       "          0.73773605, -0.7971382 ],\n",
       "        [-0.4287495 , -1.3422654 ,  0.29673722, ..., -1.0710951 ,\n",
       "         -0.2237364 ,  0.31500086],\n",
       "        ...,\n",
       "        [-0.31199235, -1.1498973 ,  0.1960739 , ..., -1.0411192 ,\n",
       "         -0.3843429 ,  0.47374406],\n",
       "        [-0.14171703, -1.3262041 ,  0.5827833 , ..., -1.3261689 ,\n",
       "          0.05203049,  0.04726318],\n",
       "        [ 0.49107635, -0.37203014,  0.54130584, ...,  0.23388322,\n",
       "          2.1104047 , -1.4227123 ]], dtype=float32),\n",
       " '*21': array([[ 1.0992174 , -1.313885  ,  0.8842725 , ..., -1.4713241 ,\n",
       "          1.9910488 , -1.5537901 ],\n",
       "        [ 0.00834931,  0.6737523 ,  0.23494306, ...,  1.321915  ,\n",
       "          0.50742745, -0.7301446 ],\n",
       "        [-0.21141587, -1.7129698 ,  0.6406167 , ..., -1.4003989 ,\n",
       "          0.27084807, -0.18131721],\n",
       "        ...,\n",
       "        [ 0.2691543 ,  0.3854017 ,  0.40249538, ...,  0.90508795,\n",
       "          1.2138973 , -1.0874175 ],\n",
       "        [ 0.01738816,  0.62897253,  0.2544945 , ...,  1.2514426 ,\n",
       "          0.8145429 , -0.8537644 ],\n",
       "        [-0.01040978,  0.6680311 ,  0.23089705, ...,  1.3221542 ,\n",
       "          0.5473097 , -0.74736106]], dtype=float32),\n",
       " '*39': array([[ 1.0526054 , -1.4449247 ,  0.9215038 , ..., -1.5940219 ,\n",
       "          1.9399796 , -1.5247389 ],\n",
       "        [ 0.11810855,  0.48496342,  0.21822426, ...,  1.1584691 ,\n",
       "          0.8262818 , -0.83792067],\n",
       "        [-0.4292177 , -1.3208002 ,  0.2781813 , ..., -1.0605519 ,\n",
       "         -0.24728405,  0.3403713 ],\n",
       "        ...,\n",
       "        [-0.3132707 , -1.1491134 ,  0.1921007 , ..., -1.0402068 ,\n",
       "         -0.38591   ,  0.47830066],\n",
       "        [-0.20103028, -1.2788794 ,  0.5129832 , ..., -1.2587221 ,\n",
       "         -0.05132832,  0.12904193],\n",
       "        [ 0.6825528 , -0.7206067 ,  0.6800891 , ..., -0.27639186,\n",
       "          2.3443182 , -1.5468537 ]], dtype=float32),\n",
       " '*49': array([[ 0.9659905 , -0.7579462 ,  0.62588465, ..., -0.49906564,\n",
       "          2.0939245 , -1.5819318 ],\n",
       "        [ 0.01100978,  0.6790128 ,  0.24691136, ...,  1.3229907 ,\n",
       "          0.5128435 , -0.7396823 ],\n",
       "        [-0.2830032 , -1.6302503 ,  0.56766003, ..., -1.3162541 ,\n",
       "          0.1592754 , -0.05913639],\n",
       "        ...,\n",
       "        [-0.31150708, -1.1498997 ,  0.20244132, ..., -1.0427679 ,\n",
       "         -0.38192287,  0.46664107],\n",
       "        [ 0.16014266, -1.5139266 ,  0.863415  , ..., -1.6164784 ,\n",
       "          0.5425752 , -0.31613663],\n",
       "        [ 0.23740742,  0.06550273,  0.36397815, ...,  0.787347  ,\n",
       "          1.6319493 , -1.1742563 ]], dtype=float32),\n",
       " '*9': array([[ 1.0967543e+00, -1.3259902e+00,  8.7546170e-01, ...,\n",
       "         -1.4772661e+00,  1.9816942e+00, -1.5535806e+00],\n",
       "        [ 8.7954961e-02,  5.2021641e-01,  2.0843761e-01, ...,\n",
       "          1.1977568e+00,  7.6691633e-01, -8.1016970e-01],\n",
       "        [-4.2806607e-01, -1.3488066e+00,  3.0236465e-01, ...,\n",
       "         -1.0749998e+00, -2.1536942e-01,  3.0708754e-01],\n",
       "        ...,\n",
       "        [-3.1155384e-01, -1.1504735e+00,  1.9573374e-01, ...,\n",
       "         -1.0407813e+00, -3.8441429e-01,  4.7412273e-01],\n",
       "        [-1.7297131e-01, -1.3044240e+00,  5.4675514e-01, ...,\n",
       "         -1.2915354e+00, -7.8502839e-04,  8.9230657e-02],\n",
       "        [ 4.6356314e-01, -3.3125988e-01,  5.2254283e-01, ...,\n",
       "          2.9397726e-01,  2.0671308e+00, -1.4019060e+00]], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allele_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4980e1d9-70eb-46e5-8821-21a65d54b23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign_category(df_row, test_alleles, test_substrates):\n",
    "    allele_unseen = df_row['Allele'] in test_alleles\n",
    "    substrate_unseen = df_row['Substrate'] in test_substrates\n",
    "    \n",
    "    if allele_unseen and substrate_unseen:\n",
    "        return 'both_unseen'\n",
    "    elif allele_unseen:\n",
    "        return 'allele_unseen'\n",
    "    elif substrate_unseen:\n",
    "        return 'substrate_unseen'\n",
    "    else:\n",
    "        return 'both_seen'      \n",
    "        \n",
    "        \n",
    " \n",
    "        \n",
    "def random_cv_split(data, n_splits=9, random_state=42):\n",
    "    \"\"\"\n",
    "    Completely random train-test splits without considering allele or substrate structure.\n",
    "    Compatible with the existing code structure.\n",
    "    \"\"\"\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Create indices for cross-validation\n",
    "    indices = np.arange(len(data))\n",
    "\n",
    "\n",
    "    # 1. target 값을 기반으로 binning (예: 10-quantile)\n",
    "    data['bins'] = pd.qcut(data['cl'], q=10, labels=False, duplicates='drop')  # duplicates='drop'은 동일 값이 많을 경우 대비\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(data, data['bins'])):\n",
    "        # Create train and test sets\n",
    "        train_df = data.iloc[train_idx].reset_index(drop=True)\n",
    "        test_df = data.iloc[test_idx].reset_index(drop=True)\n",
    "        \n",
    "        # Identify which alleles and substrates are in the test set\n",
    "        test_alleles = test_df['Allele'].unique().tolist()\n",
    "        test_substrates = test_df['Substrate'].unique().tolist()\n",
    "        \n",
    "\n",
    "        \n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "    \n",
    "    return train_dfs, test_dfs    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f819348-5966-4580-a3b1-951dee36ed52",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial\n",
    "import json\n",
    "from src.utils.training_utils import set_seed\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from torch.optim.swa_utils import AveragedModel, update_bn\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device='cuda'):\n",
    "    model.eval()\n",
    "    losses, preds, trues = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            alleles = batch['alleles'].to(device)\n",
    "            substrates = batch['substrates'].to(device)\n",
    "            allele_masks = batch['allele_masks'].to(device)\n",
    "            substrate_masks = batch['substrate_masks'].to(device)\n",
    "            values = batch['values'].to(device)\n",
    "\n",
    "            gamma, *_ = model(alleles, substrates, allele_masks, substrate_masks)\n",
    "            loss = criterion(gamma.flatten(), values.flatten())\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            p = gamma.cpu().numpy().flatten()\n",
    "            t = values.cpu().numpy().flatten()\n",
    "            mask = ~(np.isnan(p) | np.isnan(t))\n",
    "            preds.append(p[mask])\n",
    "            trues.append(t[mask])\n",
    "\n",
    "    preds = np.concatenate(preds) if preds else np.array([])\n",
    "    trues = np.concatenate(trues) if trues else np.array([])\n",
    "    r2 = r2_score(trues, preds) if len(trues) > 1 else float('nan')\n",
    "    rmse = np.sqrt(mean_squared_error(trues, preds)) if len(trues) > 0 else float('nan')\n",
    "    pearson_r = stats.pearsonr(trues, preds)[0] if len(trues) > 1 else float('nan')\n",
    "    spearman_r = stats.spearmanr(trues, preds)[0] if len(trues) > 1 else float('nan')\n",
    "    corr_avg = (pearson_r + spearman_r) / 2.0\n",
    "    return {\n",
    "        'loss': float(np.mean(losses)),\n",
    "        'r2': r2,\n",
    "        'rmse': rmse,\n",
    "        'pearson_r': pearson_r,\n",
    "        'spearman_r': spearman_r,\n",
    "        'corr_avg': corr_avg\n",
    "    }\n",
    "\n",
    "def select_diverse_models(candidates, k=10, min_epoch_gap=5):\n",
    "    \"\"\"\n",
    "    candidates: list of (metric, epoch, state_dict), sorted by metric desc\n",
    "    returns: top-K models satisfying epoch gap constraint\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    for metric, epoch, state in candidates:\n",
    "        if all(abs(epoch - sel_epoch) >= min_epoch_gap for _, sel_epoch, _ in selected):\n",
    "            selected.append((metric, epoch, state))\n",
    "        if len(selected) == k:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingWarmRestarts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    num_epochs=410,\n",
    "    lr=2e-3,\n",
    "    weight_decay=1e-4,\n",
    "    scheduler_restart_epochs=25,\n",
    "    device='cuda',\n",
    "    fold=0,\n",
    "    model_path='model_ckpts',\n",
    "    verbose=True,\n",
    "    top_k=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model, keep top_k validation checkpoints, build SWA ensemble,\n",
    "    and return training history along with SWA ensemble metrics on val and test,\n",
    "    plus top models' test metrics.\n",
    "\n",
    "    Returns:\n",
    "        train_hist, val_hist,\n",
    "        swa_state, swa_val_metrics, swa_test_metrics,\n",
    "        top_test_results (list of dict with epoch and metrics)\n",
    "    \"\"\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    steps = len(train_loader)\n",
    "    T_0 = int(steps * scheduler_restart_epochs)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    #     optimizer, T_0=T_0, T_mult=1, eta_min=1e-5\n",
    "    # )\n",
    "    warmup_steps = steps * 10  # 예: 500 step\n",
    "    # 1. Linear warmup scheduler\n",
    "    warmup_scheduler = LinearLR(optimizer, start_factor=1e-7/lr, end_factor=1.0, total_iters=warmup_steps)\n",
    "    \n",
    "    # 2. CosineAnnealingWarmRestarts\n",
    "    cosine_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=1, eta_min=1e-7)\n",
    "    \n",
    "    # 3. Sequential scheduler 조합\n",
    "    scheduler = SequentialLR(\n",
    "        optimizer,\n",
    "        schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "        milestones=[warmup_steps]\n",
    "    )\n",
    "    count = 0\n",
    "    flag = 0\n",
    "    train_hist, val_hist = [], []\n",
    "    top_models = []  # list of (corr_avg, epoch, state_dict)\n",
    "    #ema = EMA(model, beta=0.95)\n",
    "    for epoch in range(num_epochs):\n",
    "        # if epoch > 0:\n",
    "        #     ema.restore()\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            alleles = batch['alleles'].to(device)\n",
    "            substrates = batch['substrates'].to(device)\n",
    "            allele_masks = batch['allele_masks'].to(device)\n",
    "            substrate_masks = batch['substrate_masks'].to(device)\n",
    "            values = batch['values'].to(device)\n",
    "\n",
    "            gamma, *_ = model(alleles, substrates, allele_masks, substrate_masks)\n",
    "            loss = criterion(gamma.flatten(), values.flatten())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            #ema.update()\n",
    "            epoch_loss += loss.item()\n",
    "        train_hist.append(epoch_loss / len(train_loader))\n",
    "        \n",
    "            \n",
    "        #ema.apply_shadow()\n",
    "        val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        val_hist.append(val_metrics['loss'])\n",
    "        if verbose and ((epoch + 1) % scheduler_restart_epochs == 0 or epoch == num_epochs - 1):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_hist[-1]:.4f}, \"\n",
    "                  f\"Val r2: {val_metrics['r2']:.4f}, CorrAvg: {val_metrics['corr_avg']:.4f}\")\n",
    "            \n",
    "        if epoch >= 110:\n",
    "            metric = val_metrics['r2'] + val_metrics['corr_avg'] - val_metrics['rmse']\n",
    "            # collect top_k models by metric\n",
    "            top_models.append((metric, epoch, deepcopy(model.state_dict())))\n",
    "            top_models = sorted(top_models, key=lambda x: x[0], reverse=True)[:top_k]  # ← top_k 파라미터 사용\n",
    "            \n",
    "\n",
    "\n",
    "    # evaluate top_k models on test\n",
    "    top_test_results = []\n",
    "    if verbose:\n",
    "        print(\"\\n=== Top-K Models: Test Performance ===\")\n",
    "    for corr, ep, state in top_models:\n",
    "        model.load_state_dict(state)\n",
    "        test_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        top_test_results.append({'epoch': ep, **test_metrics})\n",
    "        if verbose:\n",
    "            print(f\"Epoch {ep}: Test CorrAvg={test_metrics['corr_avg']:.4f}, R2={test_metrics['r2']:.4f}, RMSE={test_metrics['rmse']:.4f}\")\n",
    "\n",
    "    # build SWA from top_k\n",
    "    swa_model = AveragedModel(model)\n",
    "    for _, _, state in top_models:\n",
    "        tmp = deepcopy(model)\n",
    "        tmp.load_state_dict(state)\n",
    "        swa_model.update_parameters(tmp)\n",
    "    #update_bn(train_loader, swa_model, device=device)\n",
    "\n",
    "\n",
    "    swa_test_metrics = evaluate(swa_model, val_loader, criterion, device)\n",
    "    swa_state = swa_model.module.state_dict() if hasattr(swa_model, 'module') else swa_model.state_dict()\n",
    "\n",
    "    # # save SWA model\n",
    "    # swa_path = f\"{model_path}/swa_model_fold{fold}.pth\"\n",
    "    # torch.save(swa_state, swa_path)\n",
    "    # if verbose:\n",
    "    #     print(f\"Saved SWA model with Val CorrAvg={swa_val_metrics['corr_avg']:.4f}, \"\n",
    "    #           f\"Test CorrAvg={swa_test_metrics['corr_avg']:.4f} at {swa_path}\")\n",
    "\n",
    "    return train_hist, val_hist, swa_state, swa_test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c938bae-f9fb-4fbe-a998-9e9a527d3987",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_cross_validation(learning_rate,\n",
    "                           train_df, test_df, allele_features, substrate_features, \n",
    "                           model_class, model_params, device, split,  \n",
    "                           output_dir='custom_cv_models',\n",
    "                           k_folds=7, num_epochs=300, seed=42):\n",
    "    \"\"\"\n",
    "    사용자 지정 하이퍼파라미터를 사용하여 k-fold 교차 검증을 수행하고    테스트 세트에서 앙상블 모델의 성능을 평가합니다.\n",
    "    \n",
    "    Args:\n",
    "        learning_rate (float): 학습률\n",
    "        train_df (DataFrame): 학습 데이터\n",
    "        test_df (DataFrame): 테스트 데이터\n",
    "        allele_features (dict): allele 특성\n",
    "        substrate_features (dict): substrate 특성\n",
    "        model_class: 모델 클래스\n",
    "        model_params (dict): 모델 파라미터\n",
    "        device (str): 학습에 사용할 디바이스 ('cuda' 또는 'cpu')\n",
    "        output_dir (str): 모델 저장 디렉토리\n",
    "        k_folds (int): fold 수\n",
    "        num_epochs (int): 에폭 수\n",
    "        seed (int): 랜덤 시드\n",
    "        \n",
    "    Returns:\n",
    "        dict: 교차 검증 및 테스트 결과\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 모델 파라미터 업데이트\n",
    "    updated_model_params = deepcopy(model_params)\n",
    "    \n",
    "    \n",
    "    # 학습 데이터의 인덱스 준비\n",
    "    train_indices = np.arange(len(train_df))\n",
    "    \n",
    "    fold_r2_scores = []\n",
    "    fold_rmse_scores = []\n",
    "    fold_pearson_r_scores = []\n",
    "    fold_spearman_r_scores = []  # Spearman 상관계수 저장 리스트 추가\n",
    "    fold_corr_avg_scores = []    # Pearson과 Spearman의 평균 저장 리스트 추가\n",
    "    best_model_states = []       # 각 fold의 최상 모델 상태 저장\n",
    "    \n",
    "    # 저장 디렉토리 생성\n",
    "    save_dir = output_dir\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 각 fold에 대해 학습 수행\n",
    "    print(f\"Starting {k_folds}-fold cross validation\")\n",
    "    print(\"=\" * 70)\n",
    "    fold_train_dfs, fold_val_dfs = random_cv_split(train_df, n_splits=k_folds)\n",
    "    \n",
    "    #max_epochs = [400, 700, 700, 100, 400, 700, 100, 500, 800, 200]\n",
    "    for fold in range(k_folds):\n",
    "        # if fold != 5:\n",
    "        #     continue\n",
    "        set_seed(seed)\n",
    "        \n",
    "        print(f\"Fold {fold+1}/{k_folds}\")\n",
    "        fold_train_df = fold_train_dfs[fold].reset_index(drop=True)\n",
    "        fold_val_df = fold_val_dfs[fold].reset_index(drop=True)\n",
    "\n",
    "       \n",
    "        # 데이터셋 생성\n",
    "        train_dataset = MoleculeProteinDataset(\n",
    "            allele_features=allele_features,\n",
    "            substrate_features=substrate_features,\n",
    "            df=fold_train_df, \n",
    "            label_name='cl'\n",
    "        )\n",
    "        \n",
    "        val_dataset = MoleculeProteinDataset(\n",
    "            allele_features=allele_features,\n",
    "            substrate_features=substrate_features,\n",
    "            df=fold_val_df, \n",
    "            label_name='cl'\n",
    "        )\n",
    "\n",
    "        test_dataset = MoleculeProteinDataset(\n",
    "            allele_features=allele_features,\n",
    "            substrate_features=substrate_features,\n",
    "            df=test_df, \n",
    "            label_name='cl'\n",
    "        )\n",
    "        # samples_weight = fold_train_df['z_score'].values\n",
    "        # samples_weight = torch.from_numpy(samples_weight)\n",
    "        # sampler = torch.utils.data.WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
    "        \n",
    "        # # 데이터 로더 생성\n",
    "        # train_loader = DataLoader(\n",
    "        #     train_dataset,\n",
    "        #     batch_size=model_params.get('batch_size', 32),\n",
    "        #     #shuffle=True,\n",
    "        #     drop_last=True,\n",
    "        #     collate_fn=MoleculeProteinCollate,\n",
    "        #     sampler = sampler\n",
    "        # )\n",
    "        # 데이터 로더 생성\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=model_params.get('batch_size', 32),\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            collate_fn=MoleculeProteinCollate\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=model_params.get('batch_size', 32),\n",
    "            shuffle=False,\n",
    "            collate_fn=MoleculeProteinCollate\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=model_params.get('batch_size', 32),\n",
    "            shuffle=False,\n",
    "            collate_fn=MoleculeProteinCollate\n",
    "        )\n",
    "        \n",
    "        # 모델 초기화\n",
    "        model = model_class(**updated_model_params)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # 임시 모델 경로\n",
    "        temp_model_path = f'{output_dir}_temp'\n",
    "        \n",
    "        # 모델 학습\n",
    "        _, _, best_model_state, best_val_metrics = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader = test_loader,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=learning_rate,\n",
    "            weight_decay=model_params.get('weight_decay', 1e-4),\n",
    "            scheduler_restart_epochs=model_params.get('restart_epochs',25),\n",
    "            device=device,\n",
    "            fold=fold,\n",
    "            model_path=temp_model_path,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        #print(best_val_metrics['epoch'])\n",
    "        \n",
    "        best_model_states.append(best_model_state)\n",
    "        \n",
    "        # R² 점수 처리\n",
    "        r2_value = best_val_metrics['r2']\n",
    "        rmse_value = best_val_metrics['rmse']\n",
    "        pearson_r_value = best_val_metrics['pearson_r']\n",
    "        spearman_r_value = best_val_metrics['spearman_r']  # Spearman r 값 가져오기\n",
    "        corr_avg_value = (pearson_r_value + spearman_r_value) / 2.0 #best_val_metrics['corr_avg']      # 상관계수 평균 값 가져오기\n",
    "        \n",
    "       \n",
    "        fold_r2_scores.append(r2_value)\n",
    "            \n",
    "        fold_rmse_scores.append(rmse_value)\n",
    "            \n",
    "        fold_pearson_r_scores.append(pearson_r_value)\n",
    "        \n",
    "        fold_spearman_r_scores.append(spearman_r_value)\n",
    "        \n",
    "        fold_corr_avg_scores.append(corr_avg_value)\n",
    "            \n",
    "        # 각 fold의 결과 출력\n",
    "        print(f\"  Fold {fold+1} - R²: {r2_value:.4f}, RMSE: {rmse_value:.4f}, PearsonR: {pearson_r_value:.4f}, SpearmanR: {spearman_r_value:.4f}, CorrAvg: {corr_avg_value:.4f}\")\n",
    "\n",
    "    \n",
    "    # CV 평균 성능 계산\n",
    "    if len(fold_r2_scores) == 0:\n",
    "        mean_r2 = 0.0\n",
    "        mean_rmse = float('inf')\n",
    "        mean_pearson_r = 0.0\n",
    "        mean_spearman_r = 0.0  # Spearman 평균 추가\n",
    "        mean_corr_avg = 0.0    # 상관계수 평균의 평균 추가\n",
    "    else:\n",
    "        mean_r2 = np.mean(fold_r2_scores)\n",
    "        valid_rmse = [score for score in fold_rmse_scores if not np.isinf(score)]\n",
    "        mean_rmse = np.mean(valid_rmse) if valid_rmse else float('inf')\n",
    "        mean_pearson_r = np.mean(fold_pearson_r_scores)\n",
    "        mean_spearman_r = np.mean(fold_spearman_r_scores)  # Spearman 평균 계산\n",
    "        mean_corr_avg = np.mean(fold_corr_avg_scores)      # 상관계수 평균의 평균 계산\n",
    "    \n",
    "    # NaN 점수 처리\n",
    "    if np.isnan(mean_r2):\n",
    "        mean_r2 = 0.0\n",
    "    if np.isnan(mean_spearman_r):\n",
    "        mean_spearman_r = 0.0\n",
    "    if np.isnan(mean_corr_avg):\n",
    "        mean_corr_avg = 0.0\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Cross-validation results\")\n",
    "    print(f\"Mean R² across {k_folds} folds: {mean_r2:.4f}\")\n",
    "    print(f\"Mean RMSE across {k_folds} folds: {mean_rmse:.4f}\")\n",
    "    print(f\"Mean Pearson r across {k_folds} folds: {mean_pearson_r:.4f}\")\n",
    "    print(f\"Mean Spearman r across {k_folds} folds: {mean_spearman_r:.4f}\")  # Spearman 결과 출력\n",
    "    print(f\"Mean Correlation Avg across {k_folds} folds: {mean_corr_avg:.4f}\")  # 상관계수 평균 결과 출력\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 고유 식별자 생성 (상관계수 평균 기준으로 변경)\n",
    "    param_id = f\"corr_avg_{mean_corr_avg:.4f}\"\n",
    "    \n",
    "    # 모델 저장\n",
    "    for fold, state_dict in enumerate(best_model_states):\n",
    "        torch.save(state_dict, f'{save_dir}/fold_{fold}_{param_id}.pth')\n",
    "    \n",
    "    # 파라미터 정보 저장 (NumPy 타입을 Python 내장 타입으로 변환)\n",
    "    param_info = {\n",
    "        'mean_r2': float(mean_r2),\n",
    "        'mean_rmse': float(mean_rmse),\n",
    "        'mean_pearson_r': float(mean_pearson_r),\n",
    "        'mean_spearman_r': float(mean_spearman_r),  # Spearman 평균 추가\n",
    "        'mean_corr_avg': float(mean_corr_avg),      # 상관계수 평균의 평균 추가\n",
    "        'fold_r2_scores': [float(x) for x in fold_r2_scores],\n",
    "        'fold_rmse_scores': [float(x) if not np.isinf(x) else \"Infinity\" for x in fold_rmse_scores],\n",
    "        'fold_pearson_r_scores': [float(x) for x in fold_pearson_r_scores],\n",
    "        'fold_spearman_r_scores': [float(x) for x in fold_spearman_r_scores],  # Spearman 점수 리스트 추가\n",
    "        'fold_corr_avg_scores': [float(x) for x in fold_corr_avg_scores],      # 상관계수 평균 리스트 추가\n",
    "        'param_id': param_id\n",
    "    }\n",
    "    \n",
    "    with open(f'{save_dir}/params_{param_id}.json', 'w') as f:\n",
    "        json.dump(param_info, f, indent=4)\n",
    "    \n",
    "    print(\"Cross-validation models saved.\")\n",
    "    \n",
    "    print(\"\\n=== 테스트 세트 평가 시작 ===\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # 테스트 세트에서 앙상블 평가\n",
    "    test_results, all_fold_predictions = evaluate_ensemble_on_test(\n",
    "        test_df=test_df,\n",
    "        allele_features=allele_features,\n",
    "        substrate_features=substrate_features,\n",
    "        model_class=model_class,\n",
    "        model_params=updated_model_params,\n",
    "        model_states=best_model_states,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return best_model_states, all_fold_predictions, test_results\n",
    "\n",
    "\n",
    "def evaluate_ensemble_on_test(test_df, allele_features, substrate_features, \n",
    "                             model_class, model_params, model_states, device):\n",
    "    \"\"\"\n",
    "    학습된 앙상블 모델의 테스트 세트 성능을 평가합니다.\n",
    "    \n",
    "    Args:\n",
    "        test_df (DataFrame): 테스트 데이터\n",
    "        allele_features (dict): allele 특성\n",
    "        substrate_features (dict): substrate 특성\n",
    "        model_class: 모델 클래스\n",
    "        model_params (dict): 모델 파라미터\n",
    "        model_states (list): 각 fold의 모델 상태 목록\n",
    "        device (str): 평가에 사용할 디바이스\n",
    "        \n",
    "    Returns:\n",
    "        dict: 테스트 평가 결과\n",
    "    \"\"\"\n",
    "    print(\"Evaluating ensemble model on test set...\")\n",
    "    \n",
    "    # 테스트 데이터셋 생성\n",
    "    test_dataset = MoleculeProteinDataset(\n",
    "        allele_features=allele_features,\n",
    "        substrate_features=substrate_features,\n",
    "        df=test_df, \n",
    "        label_name='cl'\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=model_params.get('batch_size', 32),\n",
    "        shuffle=False,\n",
    "        collate_fn=MoleculeProteinCollate\n",
    "    )\n",
    "    \n",
    "    # 타겟값 먼저 수집 (테스트셋은 항상 동일)\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            values = batch['values'].cpu().numpy()\n",
    "            targets.extend(values)\n",
    "    \n",
    "    all_targets = np.array(targets).flatten()\n",
    "    \n",
    "    # 각 fold 모델의 예측 수집\n",
    "    all_fold_predictions = []\n",
    "    \n",
    "    for fold, state_dict in enumerate(model_states):\n",
    "        model = model_class(**model_params)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        fold_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                alleles = batch['alleles'].to(device)\n",
    "                substrates = batch['substrates'].to(device)\n",
    "                allele_masks = batch['allele_masks'].to(device)\n",
    "                substrate_masks = batch['substrate_masks'].to(device)\n",
    "                \n",
    "                # 모델이 EvidentialNet인 경우, gamma가 예측값\n",
    "                gamma, _, _, _ = model(alleles, substrates, allele_masks, substrate_masks)\n",
    "                predictions = gamma.cpu().numpy()\n",
    "                fold_predictions.extend(predictions)\n",
    "        \n",
    "        all_fold_predictions.append(np.array(fold_predictions).flatten())\n",
    "    \n",
    "    # 앙상블 예측 (모든 fold의 평균)\n",
    "    ensemble_predictions = np.mean(all_fold_predictions, axis=0)\n",
    "    \n",
    "    # 크기 확인 및 문제 발생 시 디버깅 정보 출력\n",
    "    if len(ensemble_predictions) != len(all_targets):\n",
    "        print(f\"경고: 예측값 크기({len(ensemble_predictions)})와 타겟값 크기({len(all_targets)})가 일치하지 않습니다.\")\n",
    "        min_length = min(len(ensemble_predictions), len(all_targets))\n",
    "        print(f\"최소 길이({min_length})로 배열을 자릅니다.\")\n",
    "        ensemble_predictions = ensemble_predictions[:min_length]\n",
    "        all_targets = all_targets[:min_length]\n",
    "    \n",
    "    # NaN 값 처리\n",
    "    valid_indices = ~(np.isnan(ensemble_predictions) | np.isnan(all_targets))\n",
    "    \n",
    "    if np.sum(valid_indices) != len(all_targets):\n",
    "        print(\"경고: 테스트 예측에 NaN 값이 있습니다.\")\n",
    "        test_results = {\n",
    "            'r2': 0.0,\n",
    "            'rmse': float('inf'),\n",
    "            'pearson_r': 0.0,\n",
    "            'pearson_p': 1.0,\n",
    "            'spearman_r': 0.0,  # Spearman 관련 기본값 추가\n",
    "            'spearman_p': 1.0,\n",
    "            'corr_avg': 0.0     # 상관계수 평균 기본값 추가\n",
    "        }\n",
    "    else:\n",
    "        # 유효한 예측값만 사용하여 성능 평가\n",
    "        filtered_predictions = ensemble_predictions[valid_indices]\n",
    "        filtered_targets = all_targets[valid_indices]\n",
    "        \n",
    "        # 상수 배열 처리\n",
    "        if np.all(filtered_predictions == filtered_predictions[0]) or np.all(filtered_targets == filtered_targets[0]):\n",
    "            test_results = {\n",
    "                'r2': 0.0,\n",
    "                'rmse': np.sqrt(mean_squared_error(filtered_targets, filtered_predictions)),\n",
    "                'pearson_r': 0.0,\n",
    "                'pearson_p': 1.0,\n",
    "                'spearman_r': 0.0,  # Spearman 관련 기본값 추가\n",
    "                'spearman_p': 1.0,\n",
    "                'corr_avg': 0.0     # 상관계수 평균 기본값 추가\n",
    "            }\n",
    "        else:\n",
    "            try:\n",
    "                r2 = r2_score(filtered_targets, filtered_predictions)\n",
    "                rmse = np.sqrt(mean_squared_error(filtered_targets, filtered_predictions))\n",
    "                pearson_r, pearson_p = stats.pearsonr(filtered_targets, filtered_predictions)\n",
    "                spearman_r, spearman_p = stats.spearmanr(filtered_targets, filtered_predictions)  # Spearman 상관계수 계산\n",
    "                corr_avg = (pearson_r + spearman_r) / 2.0  # 상관계수 평균 계산\n",
    "                \n",
    "                test_results = {\n",
    "                    'r2': float(r2),\n",
    "                    'rmse': float(rmse),\n",
    "                    'pearson_r': float(pearson_r),\n",
    "                    'pearson_p': float(pearson_p),\n",
    "                    'spearman_r': float(spearman_r),  # Spearman 관련 결과 추가\n",
    "                    'spearman_p': float(spearman_p),\n",
    "                    'corr_avg': float(corr_avg)       # 상관계수 평균 추가\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"테스트 메트릭 계산 중 오류 발생: {str(e)}\")\n",
    "                test_results = {\n",
    "                    'r2': 0.0,\n",
    "                    'rmse': float('inf'),\n",
    "                    'pearson_r': 0.0,\n",
    "                    'pearson_p': 1.0,\n",
    "                    'spearman_r': 0.0,  # Spearman 관련 기본값 추가\n",
    "                    'spearman_p': 1.0,\n",
    "                    'corr_avg': 0.0     # 상관계수 평균 기본값 추가\n",
    "                }\n",
    "    \n",
    "    # 앙상블 테스트 결과 출력\n",
    "    print(\"\\n=== 앙상블 모델의 테스트 세트 성능 ===\")\n",
    "    print(\"-\" * 70)\n",
    "    if np.isinf(test_results['rmse']):\n",
    "        rmse_str = \"inf\"\n",
    "    else:\n",
    "        rmse_str = f\"{test_results['rmse']:.4f}\"\n",
    "        \n",
    "    print(f\"앙상블 R²       : {test_results['r2']:.4f}\")\n",
    "    print(f\"앙상블 RMSE     : {rmse_str}\")\n",
    "    print(f\"앙상블 Pearson r: {test_results['pearson_r']:.4f}\")\n",
    "    print(f\"앙상블 Spearman r: {test_results['spearman_r']:.4f}\")  # Spearman 결과 출력\n",
    "    print(f\"앙상블 Corr Avg : {test_results['corr_avg']:.4f}\")     # 상관계수 평균 결과 출력\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # 개별 fold의 테스트 성능도 계산\n",
    "    individual_fold_results = []\n",
    "    \n",
    "    print(\"\\n=== 각 Fold별 테스트 세트 성능 ===\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\")  # 테이블 헤더 수정\n",
    "    print(\"|-------|--------|--------|-----------|------------|----------|\")   # 테이블 구분선 수정\n",
    "    \n",
    "    for fold, fold_preds in enumerate(all_fold_predictions):\n",
    "        valid_indices = ~(np.isnan(fold_preds) | np.isnan(all_targets))\n",
    "        \n",
    "        if np.sum(valid_indices) < 2:\n",
    "            fold_result = {\n",
    "                'fold': fold,\n",
    "                'r2': 0.0,\n",
    "                'rmse': float('inf'),\n",
    "                'pearson_r': 0.0,\n",
    "                'pearson_p': 1.0,\n",
    "                'spearman_r': 0.0,  # Spearman 관련 기본값 추가\n",
    "                'spearman_p': 1.0,\n",
    "                'corr_avg': 0.0     # 상관계수 평균 기본값 추가\n",
    "            }\n",
    "        else:\n",
    "            filtered_preds = fold_preds[valid_indices]\n",
    "            filtered_targets = all_targets[valid_indices]\n",
    "            \n",
    "            try:\n",
    "                fold_r2 = r2_score(filtered_targets, filtered_preds)\n",
    "                fold_rmse = np.sqrt(mean_squared_error(filtered_targets, filtered_preds))\n",
    "                fold_pearson_r, fold_pearson_p = stats.pearsonr(filtered_targets, filtered_preds)\n",
    "                fold_spearman_r, fold_spearman_p = stats.spearmanr(filtered_targets, filtered_preds)  # Spearman 상관계수 계산\n",
    "                fold_corr_avg = (fold_pearson_r + fold_spearman_r) / 2.0  # 상관계수 평균 계산\n",
    "                \n",
    "                fold_result = {\n",
    "                    'fold': fold,\n",
    "                    'r2': float(fold_r2),\n",
    "                    'rmse': float(fold_rmse),\n",
    "                    'pearson_r': float(fold_pearson_r),\n",
    "                    'pearson_p': float(fold_pearson_p),\n",
    "                    'spearman_r': float(fold_spearman_r),  # Spearman 관련 결과 추가\n",
    "                    'spearman_p': float(fold_spearman_p),\n",
    "                    'corr_avg': float(fold_corr_avg)       # 상관계수 평균 추가\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"  경고: Fold {fold}의 메트릭 계산 중 오류 발생: {str(e)}\")\n",
    "                fold_result = {\n",
    "                    'fold': fold,\n",
    "                    'r2': 0.0,\n",
    "                    'rmse': float('inf'),\n",
    "                    'pearson_r': 0.0,\n",
    "                    'pearson_p': 1.0,\n",
    "                    'spearman_r': 0.0,  # Spearman 관련 기본값 추가\n",
    "                    'spearman_p': 1.0,\n",
    "                    'corr_avg': 0.0     # 상관계수 평균 기본값 추가\n",
    "                }\n",
    "        \n",
    "        individual_fold_results.append(fold_result)\n",
    "        \n",
    "        # 테이블 형식으로 출력 (Spearman과 상관계수 평균 추가)\n",
    "        if np.isinf(fold_result['rmse']):\n",
    "            rmse_str = \"  inf  \"\n",
    "        else:\n",
    "            rmse_str = f\"{fold_result['rmse']:.4f}\"\n",
    "            \n",
    "        print(f\"| {fold:^5} | {fold_result['r2']:^6.4f} | {rmse_str} | {fold_result['pearson_r']:^9.4f} | {fold_result['spearman_r']:^10.4f} | {fold_result['corr_avg']:^8.4f} |\")\n",
    "    \n",
    "    # 개별 fold들과 앙상블 성능 비교 출력\n",
    "    fold_r2_values = [res['r2'] for res in individual_fold_results]\n",
    "    fold_rmse_values = [res['rmse'] for res in individual_fold_results if not np.isinf(res['rmse'])]\n",
    "    fold_pearson_values = [res['pearson_r'] for res in individual_fold_results]\n",
    "    fold_spearman_values = [res['spearman_r'] for res in individual_fold_results]  # Spearman 값 리스트 추가\n",
    "    fold_corr_avg_values = [res['corr_avg'] for res in individual_fold_results]    # 상관계수 평균 값 리스트 추가\n",
    "    \n",
    "    print(\"\\n=== 테스트 세트 성능 요약 ===\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"개별 Fold 평균 R²       : {np.mean(fold_r2_values):.4f}\")\n",
    "    print(f\"개별 Fold 최고 R²       : {np.max(fold_r2_values):.4f} (Fold {np.argmax(fold_r2_values)})\")\n",
    "    \n",
    "    if fold_rmse_values:\n",
    "        print(f\"개별 Fold 평균 RMSE     : {np.mean(fold_rmse_values):.4f}\")\n",
    "        print(f\"개별 Fold 최저 RMSE     : {np.min(fold_rmse_values):.4f}\")\n",
    "    \n",
    "    print(f\"개별 Fold 평균 Pearson r: {np.mean(fold_pearson_values):.4f}\")\n",
    "    print(f\"개별 Fold 최고 Pearson r: {np.max(fold_pearson_values):.4f} (Fold {np.argmax(fold_pearson_values)})\")\n",
    "    \n",
    "    # Spearman과 상관계수 평균 결과 추가\n",
    "    print(f\"개별 Fold 평균 Spearman r: {np.mean(fold_spearman_values):.4f}\")\n",
    "    print(f\"개별 Fold 최고 Spearman r: {np.max(fold_spearman_values):.4f} (Fold {np.argmax(fold_spearman_values)})\")\n",
    "    print(f\"개별 Fold 평균 Corr Avg  : {np.mean(fold_corr_avg_values):.4f}\")\n",
    "    print(f\"개별 Fold 최고 Corr Avg  : {np.max(fold_corr_avg_values):.4f} (Fold {np.argmax(fold_corr_avg_values)})\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"앙상블 모델 R² (참고)   : {test_results['r2']:.4f}\")\n",
    "    print(f\"앙상블 모델 Corr Avg    : {test_results['corr_avg']:.4f}\")  # 앙상블 모델의 상관계수 평균 추가\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # 테스트 결과 반환\n",
    "    test_summary = {\n",
    "        'ensemble': test_results,\n",
    "        'individual_folds': individual_fold_results,\n",
    "        'summary': {\n",
    "            'avg_fold_r2': float(np.mean(fold_r2_values)),\n",
    "            'max_fold_r2': float(np.max(fold_r2_values)),\n",
    "            'best_fold_idx_r2': int(np.argmax(fold_r2_values)),\n",
    "            'avg_fold_pearson_r': float(np.mean(fold_pearson_values)),\n",
    "            'max_fold_pearson_r': float(np.max(fold_pearson_values)),\n",
    "            'best_fold_idx_pearson': int(np.argmax(fold_pearson_values)),\n",
    "            # Spearman과 상관계수 평균 요약 정보 추가\n",
    "            'avg_fold_spearman_r': float(np.mean(fold_spearman_values)),\n",
    "            'max_fold_spearman_r': float(np.max(fold_spearman_values)),\n",
    "            'best_fold_idx_spearman': int(np.argmax(fold_spearman_values)),\n",
    "            'avg_fold_corr_avg': float(np.mean(fold_corr_avg_values)),\n",
    "            'max_fold_corr_avg': float(np.max(fold_corr_avg_values)),\n",
    "            'best_fold_idx_corr_avg': int(np.argmax(fold_corr_avg_values))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # fold_rmse_values가 비어있지 않은 경우에만 추가\n",
    "    if fold_rmse_values:\n",
    "        test_summary['summary']['avg_fold_rmse'] = float(np.mean(fold_rmse_values))\n",
    "        test_summary['summary']['min_fold_rmse'] = float(np.min(fold_rmse_values))\n",
    "    \n",
    "    return test_summary, all_fold_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c66e384f-d42e-4a98-ac4a-49c8d7ae00cd",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.7527, RMSE: 1.1382, PearsonR: 0.8682, SpearmanR: 0.8010, CorrAvg: 0.8346\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.5650, RMSE: 1.2575, PearsonR: 0.7836, SpearmanR: 0.7665, CorrAvg: 0.7750\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7731, RMSE: 0.9785, PearsonR: 0.8804, SpearmanR: 0.8522, CorrAvg: 0.8663\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.7522, RMSE: 0.8661, PearsonR: 0.8810, SpearmanR: 0.8788, CorrAvg: 0.8799\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.7941, RMSE: 0.8364, PearsonR: 0.8956, SpearmanR: 0.8557, CorrAvg: 0.8756\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6951, RMSE: 1.0647, PearsonR: 0.8365, SpearmanR: 0.8054, CorrAvg: 0.8210\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.8213, RMSE: 0.7561, PearsonR: 0.9122, SpearmanR: 0.8916, CorrAvg: 0.9019\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.6083, RMSE: 1.1694, PearsonR: 0.7812, SpearmanR: 0.7724, CorrAvg: 0.7768\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.7332, RMSE: 0.8686, PearsonR: 0.8672, SpearmanR: 0.8350, CorrAvg: 0.8511\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7217\n",
      "Mean RMSE across 9 folds: 0.9928\n",
      "Mean Pearson r across 9 folds: 0.8562\n",
      "Mean Spearman r across 9 folds: 0.8287\n",
      "Mean Correlation Avg across 9 folds: 0.8425\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7980\n",
      "앙상블 RMSE     : 0.8289\n",
      "앙상블 Pearson r: 0.9164\n",
      "앙상블 Spearman r: 0.9003\n",
      "앙상블 Corr Avg : 0.9084\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.7596 | 0.9041 |  0.8807   |   0.8336   |  0.8571  |\n",
      "|   1   | 0.7537 | 0.9152 |  0.8990   |   0.8848   |  0.8919  |\n",
      "|   2   | 0.7500 | 0.9220 |  0.8891   |   0.8825   |  0.8858  |\n",
      "|   3   | 0.7620 | 0.8996 |  0.8968   |   0.9021   |  0.8995  |\n",
      "|   4   | 0.6188 | 1.1385 |  0.8382   |   0.7806   |  0.8094  |\n",
      "|   5   | 0.7172 | 0.9806 |  0.8753   |   0.8621   |  0.8687  |\n",
      "|   6   | 0.6791 | 1.0446 |  0.8986   |   0.8741   |  0.8863  |\n",
      "|   7   | 0.5952 | 1.1733 |  0.8325   |   0.8238   |  0.8282  |\n",
      "|   8   | 0.8175 | 0.7878 |  0.9055   |   0.8923   |  0.8989  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.7170\n",
      "개별 Fold 최고 R²       : 0.8175 (Fold 8)\n",
      "개별 Fold 평균 RMSE     : 0.9740\n",
      "개별 Fold 최저 RMSE     : 0.7878\n",
      "개별 Fold 평균 Pearson r: 0.8795\n",
      "개별 Fold 최고 Pearson r: 0.9055 (Fold 8)\n",
      "개별 Fold 평균 Spearman r: 0.8595\n",
      "개별 Fold 최고 Spearman r: 0.9021 (Fold 3)\n",
      "개별 Fold 평균 Corr Avg  : 0.8695\n",
      "개별 Fold 최고 Corr Avg  : 0.8995 (Fold 3)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7980\n",
      "앙상블 모델 Corr Avg    : 0.9084\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.6937, RMSE: 1.0878, PearsonR: 0.8455, SpearmanR: 0.8162, CorrAvg: 0.8309\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.7548, RMSE: 1.0199, PearsonR: 0.8878, SpearmanR: 0.9069, CorrAvg: 0.8973\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.6954, RMSE: 0.9656, PearsonR: 0.8527, SpearmanR: 0.8601, CorrAvg: 0.8564\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.6450, RMSE: 1.0441, PearsonR: 0.8147, SpearmanR: 0.8177, CorrAvg: 0.8162\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.8327, RMSE: 0.8079, PearsonR: 0.9170, SpearmanR: 0.8729, CorrAvg: 0.8949\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.7616, RMSE: 0.9008, PearsonR: 0.8754, SpearmanR: 0.8438, CorrAvg: 0.8596\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.5456, RMSE: 1.1931, PearsonR: 0.7600, SpearmanR: 0.7433, CorrAvg: 0.7517\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.5976, RMSE: 1.1127, PearsonR: 0.8046, SpearmanR: 0.8473, CorrAvg: 0.8259\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.7189, RMSE: 1.1535, PearsonR: 0.8492, SpearmanR: 0.8571, CorrAvg: 0.8532\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.6939\n",
      "Mean RMSE across 9 folds: 1.0317\n",
      "Mean Pearson r across 9 folds: 0.8452\n",
      "Mean Spearman r across 9 folds: 0.8406\n",
      "Mean Correlation Avg across 9 folds: 0.8429\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.8139\n",
      "앙상블 RMSE     : 0.8202\n",
      "앙상블 Pearson r: 0.9028\n",
      "앙상블 Spearman r: 0.8310\n",
      "앙상블 Corr Avg : 0.8669\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.6851 | 1.0667 |  0.8293   |   0.7626   |  0.7959  |\n",
      "|   1   | 0.7731 | 0.9055 |  0.8837   |   0.8148   |  0.8493  |\n",
      "|   2   | 0.7990 | 0.8522 |  0.8956   |   0.8123   |  0.8540  |\n",
      "|   3   | 0.6916 | 1.0557 |  0.8343   |   0.7345   |  0.7844  |\n",
      "|   4   | 0.7605 | 0.9304 |  0.8831   |   0.7788   |  0.8310  |\n",
      "|   5   | 0.8460 | 0.7461 |  0.9207   |   0.8498   |  0.8852  |\n",
      "|   6   | 0.7628 | 0.9258 |  0.8737   |   0.8808   |  0.8773  |\n",
      "|   7   | 0.8263 | 0.7923 |  0.9122   |   0.8571   |  0.8846  |\n",
      "|   8   | 0.7369 | 0.9751 |  0.8595   |   0.7680   |  0.8138  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.7646\n",
      "개별 Fold 최고 R²       : 0.8460 (Fold 5)\n",
      "개별 Fold 평균 RMSE     : 0.9166\n",
      "개별 Fold 최저 RMSE     : 0.7461\n",
      "개별 Fold 평균 Pearson r: 0.8769\n",
      "개별 Fold 최고 Pearson r: 0.9207 (Fold 5)\n",
      "개별 Fold 평균 Spearman r: 0.8065\n",
      "개별 Fold 최고 Spearman r: 0.8808 (Fold 6)\n",
      "개별 Fold 평균 Corr Avg  : 0.8417\n",
      "개별 Fold 최고 Corr Avg  : 0.8852 (Fold 5)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.8139\n",
      "앙상블 모델 Corr Avg    : 0.8669\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.8404, RMSE: 0.7791, PearsonR: 0.9253, SpearmanR: 0.8581, CorrAvg: 0.8917\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.8131, RMSE: 0.8801, PearsonR: 0.9029, SpearmanR: 0.8691, CorrAvg: 0.8860\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.8087, RMSE: 0.9340, PearsonR: 0.9217, SpearmanR: 0.9355, CorrAvg: 0.9286\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.6213, RMSE: 1.0605, PearsonR: 0.8168, SpearmanR: 0.7837, CorrAvg: 0.8003\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.8179, RMSE: 0.8380, PearsonR: 0.9151, SpearmanR: 0.8611, CorrAvg: 0.8881\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6272, RMSE: 1.0914, PearsonR: 0.8009, SpearmanR: 0.7690, CorrAvg: 0.7850\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.7396, RMSE: 0.9134, PearsonR: 0.8621, SpearmanR: 0.8665, CorrAvg: 0.8643\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.7390, RMSE: 0.8833, PearsonR: 0.8707, SpearmanR: 0.8837, CorrAvg: 0.8772\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.6142, RMSE: 1.2098, PearsonR: 0.7873, SpearmanR: 0.8108, CorrAvg: 0.7991\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7357\n",
      "Mean RMSE across 9 folds: 0.9544\n",
      "Mean Pearson r across 9 folds: 0.8670\n",
      "Mean Spearman r across 9 folds: 0.8486\n",
      "Mean Correlation Avg across 9 folds: 0.8578\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7906\n",
      "앙상블 RMSE     : 0.8626\n",
      "앙상블 Pearson r: 0.8979\n",
      "앙상블 Spearman r: 0.8867\n",
      "앙상블 Corr Avg : 0.8923\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.8179 | 0.8044 |  0.9101   |   0.9089   |  0.9095  |\n",
      "|   1   | 0.7912 | 0.8612 |  0.8943   |   0.8813   |  0.8878  |\n",
      "|   2   | 0.7259 | 0.9869 |  0.8859   |   0.8680   |  0.8769  |\n",
      "|   3   | 0.6528 | 1.1107 |  0.8281   |   0.7847   |  0.8064  |\n",
      "|   4   | 0.7582 | 0.9269 |  0.8917   |   0.8788   |  0.8853  |\n",
      "|   5   | 0.7616 | 0.9203 |  0.8940   |   0.8798   |  0.8869  |\n",
      "|   6   | 0.7958 | 0.8517 |  0.9076   |   0.9094   |  0.9085  |\n",
      "|   7   | 0.5974 | 1.1961 |  0.7974   |   0.7704   |  0.7839  |\n",
      "|   8   | 0.7374 | 0.9658 |  0.8645   |   0.8409   |  0.8527  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.7376\n",
      "개별 Fold 최고 R²       : 0.8179 (Fold 0)\n",
      "개별 Fold 평균 RMSE     : 0.9582\n",
      "개별 Fold 최저 RMSE     : 0.8044\n",
      "개별 Fold 평균 Pearson r: 0.8749\n",
      "개별 Fold 최고 Pearson r: 0.9101 (Fold 0)\n",
      "개별 Fold 평균 Spearman r: 0.8580\n",
      "개별 Fold 최고 Spearman r: 0.9094 (Fold 6)\n",
      "개별 Fold 평균 Corr Avg  : 0.8664\n",
      "개별 Fold 최고 Corr Avg  : 0.9095 (Fold 0)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7906\n",
      "앙상블 모델 Corr Avg    : 0.8923\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.8527, RMSE: 0.7289, PearsonR: 0.9239, SpearmanR: 0.9350, CorrAvg: 0.9295\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.8826, RMSE: 0.6165, PearsonR: 0.9485, SpearmanR: 0.9276, CorrAvg: 0.9380\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7869, RMSE: 0.9570, PearsonR: 0.8887, SpearmanR: 0.8241, CorrAvg: 0.8564\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.7827, RMSE: 0.8626, PearsonR: 0.8849, SpearmanR: 0.8970, CorrAvg: 0.8910\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.8112, RMSE: 0.8587, PearsonR: 0.9014, SpearmanR: 0.8719, CorrAvg: 0.8867\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6730, RMSE: 0.9858, PearsonR: 0.8447, SpearmanR: 0.7911, CorrAvg: 0.8179\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.6706, RMSE: 1.1498, PearsonR: 0.8290, SpearmanR: 0.8473, CorrAvg: 0.8382\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.8351, RMSE: 0.7529, PearsonR: 0.9228, SpearmanR: 0.9128, CorrAvg: 0.9178\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.4365, RMSE: 1.3508, PearsonR: 0.7122, SpearmanR: 0.6970, CorrAvg: 0.7046\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7479\n",
      "Mean RMSE across 9 folds: 0.9181\n",
      "Mean Pearson r across 9 folds: 0.8729\n",
      "Mean Spearman r across 9 folds: 0.8560\n",
      "Mean Correlation Avg across 9 folds: 0.8644\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.6912\n",
      "앙상블 RMSE     : 1.1024\n",
      "앙상블 Pearson r: 0.8315\n",
      "앙상블 Spearman r: 0.8734\n",
      "앙상블 Corr Avg : 0.8525\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.6289 | 1.2086 |  0.7954   |   0.8424   |  0.8189  |\n",
      "|   1   | 0.6984 | 1.0894 |  0.8366   |   0.8571   |  0.8469  |\n",
      "|   2   | 0.6363 | 1.1964 |  0.8070   |   0.8670   |  0.8370  |\n",
      "|   3   | 0.6434 | 1.1847 |  0.8076   |   0.8335   |  0.8205  |\n",
      "|   4   | 0.6709 | 1.1380 |  0.8198   |   0.8655   |  0.8427  |\n",
      "|   5   | 0.6728 | 1.1348 |  0.8253   |   0.8709   |  0.8481  |\n",
      "|   6   | 0.6563 | 1.1631 |  0.8107   |   0.8650   |  0.8379  |\n",
      "|   7   | 0.6630 | 1.1517 |  0.8184   |   0.8621   |  0.8402  |\n",
      "|   8   | 0.6587 | 1.1590 |  0.8251   |   0.8443   |  0.8347  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.6588\n",
      "개별 Fold 최고 R²       : 0.6984 (Fold 1)\n",
      "개별 Fold 평균 RMSE     : 1.1584\n",
      "개별 Fold 최저 RMSE     : 1.0894\n",
      "개별 Fold 평균 Pearson r: 0.8162\n",
      "개별 Fold 최고 Pearson r: 0.8366 (Fold 1)\n",
      "개별 Fold 평균 Spearman r: 0.8564\n",
      "개별 Fold 최고 Spearman r: 0.8709 (Fold 5)\n",
      "개별 Fold 평균 Corr Avg  : 0.8363\n",
      "개별 Fold 최고 Corr Avg  : 0.8481 (Fold 5)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.6912\n",
      "앙상블 모델 Corr Avg    : 0.8525\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.7946, RMSE: 0.9038, PearsonR: 0.8923, SpearmanR: 0.8972, CorrAvg: 0.8948\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.7973, RMSE: 0.8776, PearsonR: 0.8966, SpearmanR: 0.8834, CorrAvg: 0.8900\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7087, RMSE: 0.9157, PearsonR: 0.8449, SpearmanR: 0.8113, CorrAvg: 0.8281\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.7659, RMSE: 0.8617, PearsonR: 0.8787, SpearmanR: 0.9094, CorrAvg: 0.8940\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.8389, RMSE: 0.7258, PearsonR: 0.9222, SpearmanR: 0.9251, CorrAvg: 0.9237\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6915, RMSE: 0.9472, PearsonR: 0.8478, SpearmanR: 0.8192, CorrAvg: 0.8335\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.6466, RMSE: 1.2672, PearsonR: 0.8170, SpearmanR: 0.8143, CorrAvg: 0.8156\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.7299, RMSE: 0.9885, PearsonR: 0.8595, SpearmanR: 0.8571, CorrAvg: 0.8583\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.7057, RMSE: 1.1624, PearsonR: 0.8457, SpearmanR: 0.7985, CorrAvg: 0.8221\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7421\n",
      "Mean RMSE across 9 folds: 0.9611\n",
      "Mean Pearson r across 9 folds: 0.8672\n",
      "Mean Spearman r across 9 folds: 0.8573\n",
      "Mean Correlation Avg across 9 folds: 0.8622\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7034\n",
      "앙상블 RMSE     : 0.9921\n",
      "앙상블 Pearson r: 0.8505\n",
      "앙상블 Spearman r: 0.8369\n",
      "앙상블 Corr Avg : 0.8437\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.6170 | 1.1274 |  0.8276   |   0.8192   |  0.8234  |\n",
      "|   1   | 0.6101 | 1.1375 |  0.8125   |   0.8187   |  0.8156  |\n",
      "|   2   | 0.6793 | 1.0317 |  0.8452   |   0.8448   |  0.8450  |\n",
      "|   3   | 0.6349 | 1.1008 |  0.8205   |   0.8172   |  0.8189  |\n",
      "|   4   | 0.6271 | 1.1124 |  0.8236   |   0.8167   |  0.8202  |\n",
      "|   5   | 0.7092 | 0.9823 |  0.8504   |   0.8424   |  0.8464  |\n",
      "|   6   | 0.7000 | 0.9979 |  0.8581   |   0.8808   |  0.8694  |\n",
      "|   7   | 0.6667 | 1.0518 |  0.8322   |   0.8118   |  0.8220  |\n",
      "|   8   | 0.6262 | 1.1138 |  0.8136   |   0.7842   |  0.7989  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.6523\n",
      "개별 Fold 최고 R²       : 0.7092 (Fold 5)\n",
      "개별 Fold 평균 RMSE     : 1.0729\n",
      "개별 Fold 최저 RMSE     : 0.9823\n",
      "개별 Fold 평균 Pearson r: 0.8315\n",
      "개별 Fold 최고 Pearson r: 0.8581 (Fold 6)\n",
      "개별 Fold 평균 Spearman r: 0.8262\n",
      "개별 Fold 최고 Spearman r: 0.8808 (Fold 6)\n",
      "개별 Fold 평균 Corr Avg  : 0.8289\n",
      "개별 Fold 최고 Corr Avg  : 0.8694 (Fold 6)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7034\n",
      "앙상블 모델 Corr Avg    : 0.8437\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.8378, RMSE: 0.7922, PearsonR: 0.9154, SpearmanR: 0.8772, CorrAvg: 0.8963\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.8141, RMSE: 0.8410, PearsonR: 0.9051, SpearmanR: 0.8686, CorrAvg: 0.8869\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.8050, RMSE: 0.8331, PearsonR: 0.9070, SpearmanR: 0.8463, CorrAvg: 0.8767\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.7567, RMSE: 0.8739, PearsonR: 0.8728, SpearmanR: 0.9074, CorrAvg: 0.8901\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.6874, RMSE: 0.9914, PearsonR: 0.8562, SpearmanR: 0.8724, CorrAvg: 0.8643\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6493, RMSE: 1.0605, PearsonR: 0.8103, SpearmanR: 0.8000, CorrAvg: 0.8052\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.7071, RMSE: 1.0284, PearsonR: 0.8530, SpearmanR: 0.8266, CorrAvg: 0.8398\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.6422, RMSE: 1.2012, PearsonR: 0.8023, SpearmanR: 0.8438, CorrAvg: 0.8231\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.8216, RMSE: 0.8179, PearsonR: 0.9117, SpearmanR: 0.8936, CorrAvg: 0.9026\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7468\n",
      "Mean RMSE across 9 folds: 0.9377\n",
      "Mean Pearson r across 9 folds: 0.8704\n",
      "Mean Spearman r across 9 folds: 0.8595\n",
      "Mean Correlation Avg across 9 folds: 0.8650\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7947\n",
      "앙상블 RMSE     : 0.9043\n",
      "앙상블 Pearson r: 0.8958\n",
      "앙상블 Spearman r: 0.8478\n",
      "앙상블 Corr Avg : 0.8718\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.8048 | 0.8820 |  0.8979   |   0.8374   |  0.8677  |\n",
      "|   1   | 0.7470 | 1.0041 |  0.8681   |   0.8172   |  0.8427  |\n",
      "|   2   | 0.8045 | 0.8826 |  0.8980   |   0.8616   |  0.8798  |\n",
      "|   3   | 0.6810 | 1.1274 |  0.8258   |   0.7818   |  0.8038  |\n",
      "|   4   | 0.7046 | 1.0849 |  0.8400   |   0.8030   |  0.8215  |\n",
      "|   5   | 0.7728 | 0.9514 |  0.8792   |   0.8655   |  0.8724  |\n",
      "|   6   | 0.5870 | 1.2828 |  0.7831   |   0.7256   |  0.7543  |\n",
      "|   7   | 0.8259 | 0.8329 |  0.9147   |   0.8847   |  0.8997  |\n",
      "|   8   | 0.7890 | 0.9169 |  0.8886   |   0.8360   |  0.8623  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.7463\n",
      "개별 Fold 최고 R²       : 0.8259 (Fold 7)\n",
      "개별 Fold 평균 RMSE     : 0.9961\n",
      "개별 Fold 최저 RMSE     : 0.8329\n",
      "개별 Fold 평균 Pearson r: 0.8662\n",
      "개별 Fold 최고 Pearson r: 0.9147 (Fold 7)\n",
      "개별 Fold 평균 Spearman r: 0.8236\n",
      "개별 Fold 최고 Spearman r: 0.8847 (Fold 7)\n",
      "개별 Fold 평균 Corr Avg  : 0.8449\n",
      "개별 Fold 최고 Corr Avg  : 0.8997 (Fold 7)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7947\n",
      "앙상블 모델 Corr Avg    : 0.8718\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.7307, RMSE: 0.8948, PearsonR: 0.8985, SpearmanR: 0.9012, CorrAvg: 0.8998\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.8192, RMSE: 0.8887, PearsonR: 0.9051, SpearmanR: 0.8729, CorrAvg: 0.8890\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7823, RMSE: 1.0099, PearsonR: 0.8877, SpearmanR: 0.9133, CorrAvg: 0.9005\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.8377, RMSE: 0.7242, PearsonR: 0.9165, SpearmanR: 0.9034, CorrAvg: 0.9100\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.6366, RMSE: 1.1805, PearsonR: 0.8218, SpearmanR: 0.7374, CorrAvg: 0.7796\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6537, RMSE: 1.0654, PearsonR: 0.8168, SpearmanR: 0.7956, CorrAvg: 0.8062\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.7764, RMSE: 0.9543, PearsonR: 0.8818, SpearmanR: 0.8985, CorrAvg: 0.8901\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.6396, RMSE: 1.0470, PearsonR: 0.8297, SpearmanR: 0.8433, CorrAvg: 0.8365\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.6743, RMSE: 0.9952, PearsonR: 0.8449, SpearmanR: 0.9030, CorrAvg: 0.8739\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7278\n",
      "Mean RMSE across 9 folds: 0.9733\n",
      "Mean Pearson r across 9 folds: 0.8670\n",
      "Mean Spearman r across 9 folds: 0.8632\n",
      "Mean Correlation Avg across 9 folds: 0.8651\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7111\n",
      "앙상블 RMSE     : 1.0202\n",
      "앙상블 Pearson r: 0.8477\n",
      "앙상블 Spearman r: 0.7448\n",
      "앙상블 Corr Avg : 0.7962\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.6115 | 1.1830 |  0.7863   |   0.6941   |  0.7402  |\n",
      "|   1   | 0.6807 | 1.0725 |  0.8323   |   0.7522   |  0.7922  |\n",
      "|   2   | 0.6668 | 1.0956 |  0.8313   |   0.7596   |  0.7954  |\n",
      "|   3   | 0.6788 | 1.0757 |  0.8250   |   0.7251   |  0.7750  |\n",
      "|   4   | 0.6570 | 1.1116 |  0.8432   |   0.7862   |  0.8147  |\n",
      "|   5   | 0.6355 | 1.1458 |  0.8150   |   0.7138   |  0.7644  |\n",
      "|   6   | 0.6724 | 1.0863 |  0.8241   |   0.7049   |  0.7645  |\n",
      "|   7   | 0.6832 | 1.0683 |  0.8425   |   0.7433   |  0.7929  |\n",
      "|   8   | 0.6582 | 1.1096 |  0.8267   |   0.7458   |  0.7862  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.6605\n",
      "개별 Fold 최고 R²       : 0.6832 (Fold 7)\n",
      "개별 Fold 평균 RMSE     : 1.1054\n",
      "개별 Fold 최저 RMSE     : 1.0683\n",
      "개별 Fold 평균 Pearson r: 0.8251\n",
      "개별 Fold 최고 Pearson r: 0.8432 (Fold 4)\n",
      "개별 Fold 평균 Spearman r: 0.7361\n",
      "개별 Fold 최고 Spearman r: 0.7862 (Fold 4)\n",
      "개별 Fold 평균 Corr Avg  : 0.7806\n",
      "개별 Fold 최고 Corr Avg  : 0.8147 (Fold 4)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7111\n",
      "앙상블 모델 Corr Avg    : 0.7962\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.7639, RMSE: 1.0337, PearsonR: 0.8845, SpearmanR: 0.8416, CorrAvg: 0.8630\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.7642, RMSE: 0.9280, PearsonR: 0.8775, SpearmanR: 0.8547, CorrAvg: 0.8661\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7773, RMSE: 0.8205, PearsonR: 0.8871, SpearmanR: 0.8833, CorrAvg: 0.8852\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.8080, RMSE: 0.7484, PearsonR: 0.9242, SpearmanR: 0.9463, CorrAvg: 0.9352\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.9058, RMSE: 0.6046, PearsonR: 0.9539, SpearmanR: 0.9409, CorrAvg: 0.9474\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.5516, RMSE: 1.2224, PearsonR: 0.7621, SpearmanR: 0.7429, CorrAvg: 0.7525\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.5938, RMSE: 1.2108, PearsonR: 0.7726, SpearmanR: 0.7591, CorrAvg: 0.7658\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.6579, RMSE: 1.0458, PearsonR: 0.8269, SpearmanR: 0.9000, CorrAvg: 0.8634\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.8354, RMSE: 0.8645, PearsonR: 0.9179, SpearmanR: 0.9005, CorrAvg: 0.9092\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7398\n",
      "Mean RMSE across 9 folds: 0.9421\n",
      "Mean Pearson r across 9 folds: 0.8674\n",
      "Mean Spearman r across 9 folds: 0.8632\n",
      "Mean Correlation Avg across 9 folds: 0.8653\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7240\n",
      "앙상블 RMSE     : 0.9594\n",
      "앙상블 Pearson r: 0.8861\n",
      "앙상블 Spearman r: 0.8581\n",
      "앙상블 Corr Avg : 0.8721\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.6991 | 1.0016 |  0.8653   |   0.8680   |  0.8666  |\n",
      "|   1   | 0.6610 | 1.0631 |  0.8635   |   0.8562   |  0.8598  |\n",
      "|   2   | 0.6475 | 1.0842 |  0.8624   |   0.8394   |  0.8509  |\n",
      "|   3   | 0.6416 | 1.0932 |  0.8594   |   0.8473   |  0.8533  |\n",
      "|   4   | 0.6943 | 1.0097 |  0.8789   |   0.8320   |  0.8555  |\n",
      "|   5   | 0.6707 | 1.0478 |  0.8852   |   0.8778   |  0.8815  |\n",
      "|   6   | 0.6152 | 1.1327 |  0.8445   |   0.8591   |  0.8518  |\n",
      "|   7   | 0.6492 | 1.0815 |  0.8631   |   0.8433   |  0.8532  |\n",
      "|   8   | 0.6895 | 1.0175 |  0.8808   |   0.8601   |  0.8705  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.6631\n",
      "개별 Fold 최고 R²       : 0.6991 (Fold 0)\n",
      "개별 Fold 평균 RMSE     : 1.0590\n",
      "개별 Fold 최저 RMSE     : 1.0016\n",
      "개별 Fold 평균 Pearson r: 0.8670\n",
      "개별 Fold 최고 Pearson r: 0.8852 (Fold 5)\n",
      "개별 Fold 평균 Spearman r: 0.8537\n",
      "개별 Fold 최고 Spearman r: 0.8778 (Fold 5)\n",
      "개별 Fold 평균 Corr Avg  : 0.8603\n",
      "개별 Fold 최고 Corr Avg  : 0.8815 (Fold 5)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7240\n",
      "앙상블 모델 Corr Avg    : 0.8721\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.7151, RMSE: 0.9610, PearsonR: 0.8547, SpearmanR: 0.8038, CorrAvg: 0.8292\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.7908, RMSE: 0.9404, PearsonR: 0.9003, SpearmanR: 0.8892, CorrAvg: 0.8947\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7793, RMSE: 1.0353, PearsonR: 0.8873, SpearmanR: 0.8670, CorrAvg: 0.8772\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.7603, RMSE: 0.8289, PearsonR: 0.8759, SpearmanR: 0.8685, CorrAvg: 0.8722\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.7971, RMSE: 0.8082, PearsonR: 0.9003, SpearmanR: 0.8621, CorrAvg: 0.8812\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.6863, RMSE: 1.0706, PearsonR: 0.8522, SpearmanR: 0.8404, CorrAvg: 0.8463\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.6198, RMSE: 1.1501, PearsonR: 0.8135, SpearmanR: 0.7153, CorrAvg: 0.7644\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.7863, RMSE: 0.9391, PearsonR: 0.8938, SpearmanR: 0.9212, CorrAvg: 0.9075\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.6974, RMSE: 0.9252, PearsonR: 0.8352, SpearmanR: 0.8094, CorrAvg: 0.8223\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7369\n",
      "Mean RMSE across 9 folds: 0.9621\n",
      "Mean Pearson r across 9 folds: 0.8681\n",
      "Mean Spearman r across 9 folds: 0.8419\n",
      "Mean Correlation Avg across 9 folds: 0.8550\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.6662\n",
      "앙상블 RMSE     : 1.0989\n",
      "앙상블 Pearson r: 0.8598\n",
      "앙상블 Spearman r: 0.8788\n",
      "앙상블 Corr Avg : 0.8693\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.6063 | 1.1935 |  0.8571   |   0.8562   |  0.8566  |\n",
      "|   1   | 0.6561 | 1.1154 |  0.8468   |   0.8631   |  0.8549  |\n",
      "|   2   | 0.5318 | 1.3015 |  0.8185   |   0.8374   |  0.8280  |\n",
      "|   3   | 0.6022 | 1.1997 |  0.8462   |   0.8635   |  0.8549  |\n",
      "|   4   | 0.5636 | 1.2565 |  0.8289   |   0.8665   |  0.8477  |\n",
      "|   5   | 0.6330 | 1.1523 |  0.8363   |   0.8389   |  0.8376  |\n",
      "|   6   | 0.6347 | 1.1496 |  0.8255   |   0.8177   |  0.8216  |\n",
      "|   7   | 0.6213 | 1.1705 |  0.8263   |   0.8187   |  0.8225  |\n",
      "|   8   | 0.6156 | 1.1794 |  0.8360   |   0.8606   |  0.8483  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.6072\n",
      "개별 Fold 최고 R²       : 0.6561 (Fold 1)\n",
      "개별 Fold 평균 RMSE     : 1.1909\n",
      "개별 Fold 최저 RMSE     : 1.1154\n",
      "개별 Fold 평균 Pearson r: 0.8358\n",
      "개별 Fold 최고 Pearson r: 0.8571 (Fold 0)\n",
      "개별 Fold 평균 Spearman r: 0.8470\n",
      "개별 Fold 최고 Spearman r: 0.8665 (Fold 4)\n",
      "개별 Fold 평균 Corr Avg  : 0.8414\n",
      "개별 Fold 최고 Corr Avg  : 0.8566 (Fold 0)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.6662\n",
      "앙상블 모델 Corr Avg    : 0.8693\n",
      "----------------------------------------------------------------------\n",
      "Starting 9-fold cross validation\n",
      "======================================================================\n",
      "Fold 1/9\n",
      "  Fold 1 - R²: 0.7417, RMSE: 1.0716, PearsonR: 0.8661, SpearmanR: 0.8438, CorrAvg: 0.8549\n",
      "Fold 2/9\n",
      "  Fold 2 - R²: 0.6835, RMSE: 1.0368, PearsonR: 0.8270, SpearmanR: 0.8452, CorrAvg: 0.8361\n",
      "Fold 3/9\n",
      "  Fold 3 - R²: 0.7727, RMSE: 0.8155, PearsonR: 0.9079, SpearmanR: 0.9043, CorrAvg: 0.9061\n",
      "Fold 4/9\n",
      "  Fold 4 - R²: 0.7055, RMSE: 0.9718, PearsonR: 0.8433, SpearmanR: 0.7936, CorrAvg: 0.8184\n",
      "Fold 5/9\n",
      "  Fold 5 - R²: 0.8108, RMSE: 0.7783, PearsonR: 0.9037, SpearmanR: 0.8571, CorrAvg: 0.8804\n",
      "Fold 6/9\n",
      "  Fold 6 - R²: 0.7256, RMSE: 1.0382, PearsonR: 0.8763, SpearmanR: 0.8783, CorrAvg: 0.8773\n",
      "Fold 7/9\n",
      "  Fold 7 - R²: 0.5342, RMSE: 1.3549, PearsonR: 0.7393, SpearmanR: 0.7581, CorrAvg: 0.7487\n",
      "Fold 8/9\n",
      "  Fold 8 - R²: 0.8422, RMSE: 0.7838, PearsonR: 0.9327, SpearmanR: 0.8985, CorrAvg: 0.9156\n",
      "Fold 9/9\n",
      "  Fold 9 - R²: 0.8062, RMSE: 0.8093, PearsonR: 0.9030, SpearmanR: 0.9246, CorrAvg: 0.9138\n",
      "======================================================================\n",
      "Cross-validation results\n",
      "Mean R² across 9 folds: 0.7358\n",
      "Mean RMSE across 9 folds: 0.9622\n",
      "Mean Pearson r across 9 folds: 0.8666\n",
      "Mean Spearman r across 9 folds: 0.8560\n",
      "Mean Correlation Avg across 9 folds: 0.8613\n",
      "======================================================================\n",
      "Cross-validation models saved.\n",
      "\n",
      "=== 테스트 세트 평가 시작 ===\n",
      "----------------------------------------------------------------------\n",
      "Evaluating ensemble model on test set...\n",
      "\n",
      "=== 앙상블 모델의 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "앙상블 R²       : 0.7144\n",
      "앙상블 RMSE     : 1.0354\n",
      "앙상블 Pearson r: 0.8675\n",
      "앙상블 Spearman r: 0.7961\n",
      "앙상블 Corr Avg : 0.8318\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=== 각 Fold별 테스트 세트 성능 ===\n",
      "----------------------------------------------------------------------\n",
      "| Fold  |   R²   |  RMSE  | Pearson r | Spearman r | Corr Avg |\n",
      "|-------|--------|--------|-----------|------------|----------|\n",
      "|   0   | 0.7334 | 1.0004 |  0.8726   |   0.8163   |  0.8444  |\n",
      "|   1   | 0.7191 | 1.0268 |  0.8657   |   0.7901   |  0.8279  |\n",
      "|   2   | 0.6359 | 1.1691 |  0.8332   |   0.7660   |  0.7996  |\n",
      "|   3   | 0.6899 | 1.0789 |  0.8670   |   0.8192   |  0.8431  |\n",
      "|   4   | 0.6231 | 1.1893 |  0.8426   |   0.7975   |  0.8201  |\n",
      "|   5   | 0.6884 | 1.0815 |  0.8729   |   0.8429   |  0.8579  |\n",
      "|   6   | 0.6454 | 1.1537 |  0.8194   |   0.7409   |  0.7802  |\n",
      "|   7   | 0.7075 | 1.0479 |  0.8638   |   0.7714   |  0.8176  |\n",
      "|   8   | 0.6914 | 1.0762 |  0.8629   |   0.8187   |  0.8408  |\n",
      "\n",
      "=== 테스트 세트 성능 요약 ===\n",
      "----------------------------------------------------------------------\n",
      "개별 Fold 평균 R²       : 0.6816\n",
      "개별 Fold 최고 R²       : 0.7334 (Fold 0)\n",
      "개별 Fold 평균 RMSE     : 1.0915\n",
      "개별 Fold 최저 RMSE     : 1.0004\n",
      "개별 Fold 평균 Pearson r: 0.8555\n",
      "개별 Fold 최고 Pearson r: 0.8729 (Fold 5)\n",
      "개별 Fold 평균 Spearman r: 0.7959\n",
      "개별 Fold 최고 Spearman r: 0.8429 (Fold 5)\n",
      "개별 Fold 평균 Corr Avg  : 0.8257\n",
      "개별 Fold 최고 Corr Avg  : 0.8579 (Fold 5)\n",
      "----------------------------------------------------------------------\n",
      "앙상블 모델 R² (참고)   : 0.7144\n",
      "앙상블 모델 Corr Avg    : 0.8318\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##### 사용 예시\n",
    "lr = 0.002 # 사용자 지정 학습률\n",
    "dropout_rate = 0.1\n",
    "# 모델 파라미터 설정\n",
    "model_params = {\n",
    "    'mol_input_dim': 300,\n",
    "    'prot_input_dim': 300,\n",
    "    'hidden_dim': 64,  # Default value, will be updated during optimization\n",
    "    'num_heads': 1,\n",
    "    'drop_out': dropout_rate   # Will be overridden by unified dropout rate\n",
    "}\n",
    "\n",
    "\n",
    "# 교차 검증 및 테스트 실행\n",
    "results_list = []\n",
    "for i in range(10):\n",
    "    # if i != 3:\n",
    "    #     continue\n",
    "    results = custom_cross_validation(\n",
    "        learning_rate=lr,\n",
    "        train_df=train_df_list[i],\n",
    "        test_df=test_df_list[i],\n",
    "        allele_features=allele_features,\n",
    "        substrate_features=substrate_features,\n",
    "        model_class=InteractionModel,  # 모델 클래스\n",
    "        model_params=model_params,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        output_dir='der_cv_models',\n",
    "        k_folds=9,\n",
    "        num_epochs=410,\n",
    "        seed=42,\n",
    "        split = i\n",
    "    )\n",
    "    results_list.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0065cf9-ad2f-4d46-a65f-bbcd9c0bf1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5d5e72f2-aa11-45e0-80a6-8d6b77c8c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge Test R2:  0.740744378814883 ± 0.050275434531143214\n",
      "Averge Test RMSE:  0.962435269355774 ± 0.09960069047338244\n",
      "Averge Test Pearson:  0.8755895376205445 ± 0.026605668567345156\n",
      "Averge Test Spearman:  0.845402828539647 ± 0.044293238323725476\n"
     ]
    }
   ],
   "source": [
    "val_r2 = []\n",
    "val_rmse = []\n",
    "val_p = []\n",
    "val_s = []\n",
    "for i in range(10):\n",
    "    val_r2.append(results_list[i][2]['ensemble']['r2'])\n",
    "    val_rmse.append(results_list[i][2]['ensemble']['rmse'])\n",
    "    val_p.append(results_list[i][2]['ensemble']['pearson_r'])\n",
    "    val_s.append(results_list[i][2]['ensemble']['spearman_r'])\n",
    "print(\"Averge Test R2: \", np.mean(val_r2), \"±\", np.std(val_r2))\n",
    "print(\"Averge Test RMSE: \", np.mean(val_rmse), \"±\", np.std(val_rmse))\n",
    "print(\"Averge Test Pearson: \", np.mean(val_p), \"±\", np.std(val_p))\n",
    "print(\"Averge Test Spearman: \", np.mean(val_s), \"±\", np.std(val_s))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c2acd09-0365-41e8-a53e-50e3db055962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8679670274623814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from src.utils.proj_dataset import MoleculeProteinDataset, MoleculeProteinCollate\n",
    "\n",
    "from src.proj_model import InteractionModel\n",
    "\n",
    "with open(\"data/cyp2d6_nested_STCV_split_250727.pkl\", \"rb\") as f:\n",
    "    (train_df_list, test_df_list) = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(\"data/CYP2D6_MT_KIT_ESM3_250624.pkl\", \"rb\") as f:\n",
    "    allele_features = pickle.load(f)\n",
    "with open(\"data/MoleBERT_Substrate_NoPreMoleBERT_KIT_0624.pkl\", \"rb\") as f:\n",
    "    substrate_features = pickle.load(f)\n",
    "\n",
    "for key in substrate_features.keys():\n",
    "    mat = substrate_features[key]\n",
    "    global_emb = np.expand_dims(np.mean(mat, axis = 0), axis=0)\n",
    "    rev_mat = np.concatenate([global_emb, mat], axis = 0)\n",
    "    substrate_features[key] = rev_mat   \n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "test_df = pd.read_csv(\"../deep_cyp/data/cyp2d6_final_ours_preprocessed_250408.csv\")\n",
    "\n",
    "model_states = []\n",
    "dropout_rate = 0.1\n",
    "model_params = {\n",
    "    'mol_input_dim': 300,\n",
    "    'prot_input_dim': 300,\n",
    "    'hidden_dim': 64,  # Default value, will be updated during optimization\n",
    "    'num_heads': 1,\n",
    "    'drop_out': dropout_rate   # Will be overridden by unified dropout rate\n",
    "}\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "r2_list = []\n",
    "all_fold_predictions_test = []\n",
    "for i in range(10):\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    best_r2 = -100\n",
    "    \n",
    "    for j in range(9):\n",
    "        test_dataset = MoleculeProteinDataset(\n",
    "            allele_features=allele_features,\n",
    "            substrate_features=substrate_features,\n",
    "            df=test_df, \n",
    "            label_name='cl'\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=model_params.get('batch_size', 32),\n",
    "            shuffle=False,\n",
    "            collate_fn=MoleculeProteinCollate\n",
    "        )\n",
    "        model = InteractionModel(**model_params)\n",
    "        model.load_state_dict(results_list[i][0][j])\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        \n",
    "        targets = []\n",
    "        fold_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                alleles = batch['alleles'].to(device)\n",
    "                substrates = batch['substrates'].to(device)\n",
    "                allele_masks = batch['allele_masks'].to(device)\n",
    "                substrate_masks = batch['substrate_masks'].to(device)\n",
    "                \n",
    "                # 모델이 EvidentialNet인 경우, gamma가 예측값\n",
    "                gamma, _, _, _ = model(alleles, substrates, allele_masks, substrate_masks)\n",
    "                predictions = gamma.cpu().numpy()\n",
    "                values = batch['values'].cpu().numpy()\n",
    "                targets.extend(values)\n",
    "                fold_predictions.extend(predictions)\n",
    "\n",
    "        r2 = r2_score(np.array(targets).flatten(), np.array(fold_predictions).flatten())\n",
    "        # if r2 > best_r2:\n",
    "        #     best_r2 = r2\n",
    "        #     best_pred_set = np.array(fold_predictions).flatten()\n",
    "            #print(r2)\n",
    "        r2_list.append(r2)\n",
    "        all_fold_predictions_test.append(np.array(fold_predictions).flatten())\n",
    "\n",
    "        \n",
    "\n",
    "        # 앙상블 예측 (모든 fold의 평균)\n",
    "ensemble_predictions_test = np.mean(all_fold_predictions_test, axis=0)\n",
    "test_df['pred'] = ensemble_predictions_test\n",
    "# Allele과 Substrate 기준으로 *1에 대한 relative pred 값 계산\n",
    "# sns.scatterplot(test_df, x='cl', y='pred')\n",
    "# plt.show()\n",
    "r2 = r2_score(np.array(targets).flatten(), np.array(fold_predictions).flatten())\n",
    "print(r2)\n",
    "    \n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff67f5ef-d376-4973-8a75-479641c2a647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28 56 70 29  2 86 39 63 47 84  7 55 42 16 58 66 41 59 24 30 74 88 23 14\n",
      " 89 85 32 50 31 45 12 40 34  3 22 65 18 37 13 81 71 61 82 73 48 69 54 51\n",
      " 62 27 52  8 43 64 57 79 36 67 10 83 53 60 33 75  5  6 76 77  1 68 20 72\n",
      "  9  0 11 17 19 38 49 35 26 46 80 15 87 78 44 25  4 21]\n"
     ]
    }
   ],
   "source": [
    "# 또는 더 간단하게\n",
    "def get_top_n_indices_simple(lst, n):\n",
    "    return np.argsort(lst)[-n:][::-1]\n",
    "\n",
    "top_indices = get_top_n_indices_simple(r2_list, 90)\n",
    "print(top_indices)  # [6 2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1e814ed-be44-4974-9c65-9c3af9d28627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_states = []\n",
    "for i in range(10):\n",
    "    for j in range(9):\n",
    "        if (i * 9 + j) in top_indices:\n",
    "            model_states.append(results_list[i][0][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecea8b3b-9874-46c3-adf6-62d0d0815e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/cyp_top10_models_ckpts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_states, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "dee52973-b72f-43eb-b1b0-c3169d64171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(\"data/cyp2d6_final_293ft_external_0808.csv\")\n",
    "test_df['cl_rev'] = test_df['cl'].map(lambda x: np.log1p(x))\n",
    "\n",
    "with open(\"data/CYP2D6_external_public_293FT_ESM3_0807.pkl\", \"rb\") as f:\n",
    "    allele_features = pickle.load(f)\n",
    "with open(\"data/MoleBERT_Substrate_NoPreMoleBERT_External_250602.pkl\", \"rb\") as f:\n",
    "    substrate_features = pickle.load(f)\n",
    "\n",
    "for key in substrate_features.keys():\n",
    "    mat = substrate_features[key]\n",
    "    global_emb = np.expand_dims(np.mean(mat, axis = 0), axis=0)\n",
    "    rev_mat = np.concatenate([global_emb, mat], axis = 0)\n",
    "    substrate_features[key] = rev_mat    \n",
    "\n",
    "model_states = []\n",
    "for i in range(10):\n",
    "    for j in range(9):\n",
    "        model_states.append(results_list[i][0][j])\n",
    "\n",
    "from src.utils.proj_dataset import MoleculeProteinDataset, MoleculeProteinCollate\n",
    "\n",
    "from src.proj_model import InteractionModel\n",
    "\n",
    "\n",
    "\n",
    "dropout_rate = 0.1\n",
    "model_params = {\n",
    "    'mol_input_dim': 300,\n",
    "    'prot_input_dim': 300,\n",
    "    'hidden_dim': 64,  # Default value, will be updated during optimization\n",
    "    'num_heads': 1,\n",
    "    'drop_out': dropout_rate   # Will be overridden by unified dropout rate\n",
    "}\n",
    "device = 'cuda'\n",
    "\n",
    "# 테스트 데이터셋 생성\n",
    "test_dataset = MoleculeProteinDataset(\n",
    "    allele_features=allele_features,\n",
    "    substrate_features=substrate_features,\n",
    "    df=test_df, \n",
    "    label_name='cl_rev'\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=model_params.get('batch_size', 32),\n",
    "    shuffle=False,\n",
    "    collate_fn=MoleculeProteinCollate\n",
    ")\n",
    "\n",
    "# 타겟값 먼저 수집 (테스트셋은 항상 동일)\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        values = batch['values'].cpu().numpy()\n",
    "        targets.extend(values)\n",
    "\n",
    "all_targets = np.array(targets).flatten()\n",
    "\n",
    "# 각 fold 모델의 예측 수집\n",
    "all_fold_predictions = []\n",
    "\n",
    "for fold, state_dict in enumerate(model_states):\n",
    "    model = InteractionModel(**model_params)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    fold_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            alleles = batch['alleles'].to(device)\n",
    "            substrates = batch['substrates'].to(device)\n",
    "            allele_masks = batch['allele_masks'].to(device)\n",
    "            substrate_masks = batch['substrate_masks'].to(device)\n",
    "            \n",
    "            # 모델이 EvidentialNet인 경우, gamma가 예측값\n",
    "            gamma, _, _, _ = model(alleles, substrates, allele_masks, substrate_masks)\n",
    "            predictions = gamma.cpu().numpy()\n",
    "            fold_predictions.extend(predictions)\n",
    "    \n",
    "    all_fold_predictions.append(np.array(fold_predictions).flatten())\n",
    "# 앙상블 예측 (모든 fold의 평균)\n",
    "ensemble_predictions = np.mean(all_fold_predictions, axis=0)\n",
    "test_df['log_pred'] = ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "id": "884d1305-fda5-4ac7-b5a0-47c352e345ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# 파라미터\n",
    "WT_NAME = 'cyp2d6*1'\n",
    "\n",
    "# 1) WT 인덱스(약물별) 만들기\n",
    "wt_rows = test_df[test_df['Allele'] == WT_NAME].copy()\n",
    "if wt_rows.empty:\n",
    "    raise ValueError(\"WT 행이 없습니다. WT_NAME을 확인하세요.\")\n",
    "\n",
    "# 관측/예측의 WT 맵(로그, z)\n",
    "wt_log_obs = wt_rows.set_index('Substrate')['cl_rev'].to_dict()\n",
    "wt_log_pred = wt_rows.set_index('Substrate')['log_pred'].to_dict()\n",
    "\n",
    "\n",
    "# 2) 각 행에 대해 RC 계산 (WT 자신은 NaN 처리)\n",
    "def safe_diff(val, anchor):\n",
    "    try:\n",
    "        return val - anchor\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "test_df['RC_log_obs']  = test_df.apply(lambda r: safe_diff(r['cl_rev'],   wt_log_obs.get(r['Substrate'], np.nan)), axis=1)\n",
    "test_df['RC_log_pred'] = test_df.apply(lambda r: safe_diff(r['log_pred'], wt_log_pred.get(r['Substrate'], np.nan)), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# 3) (선택) 배수로 역변환\n",
    "test_df['RC_ratio_obs']  = np.exp(test_df['RC_log_obs'])\n",
    "test_df['RC_ratio_pred'] = np.exp(test_df['RC_log_pred'])\n",
    "\n",
    "# 4) 평가 지표 (WT 행 제외)\n",
    "mask = (test_df['Allele'] != WT_NAME) & test_df[['RC_log_obs','RC_log_pred','RC_ratio_obs','RC_ratio_pred']].notna().all(axis=1)\n",
    "eval_df = test_df.loc[mask].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "077ced28-1c79-43b7-ab55-4951a5625a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 1251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "8b7a65ee-67a7-4d71-a077-5726e86c5d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x7fb498cbc470>"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(data=eval_df, x = 'RC_log_obs', y='RC_log_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "26a20d12-31b8-4bfc-acb1-a787e43cce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_concordance_index(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Concordance Index (C-index) 계산\n",
    "    C-index는 모든 쌍에 대해 예측 순서가 실제 순서와 일치하는 비율을 측정\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: 실제값\n",
    "    y_pred: 예측값\n",
    "    \n",
    "    Returns:\n",
    "    float: C-index 값 (0.5 = 랜덤, 1.0 = 완벽한 예측)\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    concordant = 0\n",
    "    total_pairs = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # 실제 값이 다른 경우만 고려 (동점 제외)\n",
    "            if y_true[i] != y_true[j]:\n",
    "                total_pairs += 1\n",
    "                # 실제 순서와 예측 순서가 일치하면 concordant\n",
    "                if (y_true[i] < y_true[j] and y_pred[i] < y_pred[j]) or \\\n",
    "                   (y_true[i] > y_true[j] and y_pred[i] > y_pred[j]):\n",
    "                    concordant += 1\n",
    "    \n",
    "    if total_pairs == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return concordant / total_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "id": "fe51a95f-69da-427e-92ed-8830665dfd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7103174603174603 0.41980280326088576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "r2 = r2_score(eval_df['RC_log_obs'], eval_df['RC_log_pred'])\n",
    "rmse = np.sqrt(mean_squared_error(eval_df['RC_log_obs'], eval_df['RC_log_pred']))\n",
    "\n",
    "# 상관계수 지표들\n",
    "pearson_corr, pearson_p = pearsonr(eval_df['RC_log_obs'], eval_df['RC_log_pred'])\n",
    "spearman_corr, spearman_p = spearmanr(eval_df['RC_log_obs'],eval_df['RC_log_pred'])\n",
    "c_index = calculate_concordance_index(eval_df['RC_log_obs'].values, eval_df['RC_log_pred'].values)\n",
    "kendalltau = kendalltau(eval_df['RC_log_obs'], eval_df['RC_log_pred']).correlation\n",
    "print(c_index, kendalltau)\n",
    "#kendall_tau, kendall_p = kendalltau(y_true_clean, y_pred_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_cyp",
   "language": "python",
   "name": "deep_cyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
