{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d561b70-3eb9-43ea-9d24-4a568b1a342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  7 15:39:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:65:00.0 Off |                  Off |\n",
      "| 74%   33C    P8             15W /  450W |   11853MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    On  |   00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   43C    P0             83W /  350W |   17352MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    162942      C   ...miniconda3/envs/deep_cyp/bin/python      11454MiB |\n",
      "|    0   N/A  N/A   2635381      C   ...miniconda3/envs/deep_cyp/bin/python        384MiB |\n",
      "|    1   N/A  N/A     89917      C   ...miniconda3/envs/deep_cyp/bin/python        798MiB |\n",
      "|    1   N/A  N/A    162942      C   ...miniconda3/envs/deep_cyp/bin/python      11528MiB |\n",
      "|    1   N/A  N/A   1024935      C   ...miniconda3/envs/deep_cyp/bin/python        734MiB |\n",
      "|    1   N/A  N/A   1045709      C   ...miniconda3/envs/deep_cyp/bin/python        950MiB |\n",
      "|    1   N/A  N/A   1109193      C   ...miniconda3/envs/deep_cyp/bin/python        970MiB |\n",
      "|    1   N/A  N/A   1649338      C   ...miniconda3/envs/deep_cyp/bin/python        638MiB |\n",
      "|    1   N/A  N/A   3603275      C   ...miniconda3/envs/deep_cyp/bin/python        766MiB |\n",
      "|    1   N/A  N/A   4009804      C   ...miniconda3/envs/deep_cyp/bin/python        920MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a23a573-43b8-47b7-9014-11582d446e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from src.utils.training_utils import set_seed\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16360039-3c5d-4e8d-9a8c-b1c4b15c8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.utils.esmfinetune import VarDataset, VarCollator\n",
    "from src.utils.esmfinetune import MultiTaskVarDataset, MultiTaskVarCollator\n",
    "from src.varmodel_MT_AllLoRA_ESM3_proj import CYPVarAM\n",
    "#from src.varmodel import CYPVarAM\n",
    "\n",
    "from transformers import AutoTokenizer, EsmModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "esm_model = AutoModelForMaskedLM.from_pretrained('Synthyra/ESMplusplus_small', trust_remote_code=True)\n",
    "tokenizer = esm_model.tokenizer\n",
    "set_seed(42)\n",
    "intermed_list = []\n",
    "for i in range(30):\n",
    "    if i > 24:\n",
    "        intermed_list.append(str(i)+\".attn.layernorm_qkv.1\")\n",
    "        intermed_list.append(str(i)+\".attn.out_proj\")\n",
    "        intermed_list.append(str(i)+\".ffn.1\")\n",
    "        intermed_list.append(str(i)+\".ffn.3\")\n",
    "       \n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    bias=\"none\",\n",
    "    #use_dora=True,\n",
    "    target_modules=intermed_list#[\"layernorm_qkv.1\", \"out_proj\", \"ffn.1\", \"ffn.3\"]#\"query\", \"key\", \"value\", \"dense\"] + intermed_list\n",
    ")\n",
    "lora_esm_model = get_peft_model(esm_model, config)\n",
    "\n",
    "# for param in esm_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "model = CYPVarAM(esm_model = lora_esm_model, drop_att = 0.1, drop_pff = 0.1,  input_size = 960, hidden_size = 300, num_heads = 6, num_tasks = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918c838a-1e62-480a-a26a-bce0d557e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CYPVarAM(\n",
       "  (am_feature): Featurizer(\n",
       "    (esm): PeftModel(\n",
       "      (base_model): LoraModel(\n",
       "        (model): ESMplusplusForMaskedLM(\n",
       "          (embed): Embedding(64, 960)\n",
       "          (transformer): TransformerStack(\n",
       "            (blocks): ModuleList(\n",
       "              (0-24): 25 x UnifiedTransformerBlock(\n",
       "                (attn): MultiHeadAttention(\n",
       "                  (layernorm_qkv): Sequential(\n",
       "                    (0): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=960, out_features=2880, bias=False)\n",
       "                  )\n",
       "                  (out_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "                  (q_ln): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                  (k_ln): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                  (rotary): RotaryEmbedding()\n",
       "                )\n",
       "                (ffn): Sequential(\n",
       "                  (0): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): Linear(in_features=960, out_features=5120, bias=False)\n",
       "                  (2): SwiGLU()\n",
       "                  (3): Linear(in_features=2560, out_features=960, bias=False)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (25-29): 5 x UnifiedTransformerBlock(\n",
       "                (attn): MultiHeadAttention(\n",
       "                  (layernorm_qkv): Sequential(\n",
       "                    (0): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=960, out_features=2880, bias=False)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Identity()\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=960, out_features=16, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=16, out_features=2880, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                      (lora_magnitude_vector): ModuleDict()\n",
       "                    )\n",
       "                  )\n",
       "                  (out_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=960, out_features=960, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=960, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=960, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (q_ln): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                  (k_ln): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                  (rotary): RotaryEmbedding()\n",
       "                )\n",
       "                (ffn): Sequential(\n",
       "                  (0): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "                  (1): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=960, out_features=5120, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=960, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=5120, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (2): SwiGLU()\n",
       "                  (3): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=2560, out_features=960, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=2560, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=960, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (sequence_head): Sequential(\n",
       "            (0): Linear(in_features=960, out_features=960, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "            (3): Linear(in_features=960, out_features=64, bias=True)\n",
       "          )\n",
       "          (ce_loss): CrossEntropyLoss()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cross_attn): Transformer(\n",
       "      (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): MultiHeadAttention(\n",
       "        (q_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (k_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (v_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (o_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (pFF): PositionWiseFeedForward(\n",
       "        (W1): Linear(in_features=300, out_features=1200, bias=True)\n",
       "        (W2): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (proj_out): Linear(in_features=960, out_features=300, bias=True)\n",
       "    (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (am_predict): MultiTaskPredictor(\n",
       "    (task_heads): ModuleList(\n",
       "      (0-2): 3 x Predictor(\n",
       "        (W1): Linear(in_features=300, out_features=300, bias=True)\n",
       "        (W2): Linear(in_features=300, out_features=1, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./esm3_MT_small_raw_5layer/checkpoint-11694/model.safetensors\"\n",
    "loaded = load_file(file_path)\n",
    "model.load_state_dict(loaded, strict=True)\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181097e4-cde7-4dc7-9759-a84ccfa4267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/uniprot_cyp_variant_protvar_250709.pkl\", \"rb\") as f:\n",
    "    all_cyp_variants_rev = pickle.load(f)\n",
    "wt_seq_dict = all_cyp_variants_rev[all_cyp_variants_rev['variant']=='WT'][['Gene', 'Sequence']].set_index('Gene').to_dict()['Sequence']\n",
    "all_cyp_variants_rev['wt_seq'] = all_cyp_variants_rev['Gene'].map(lambda x: wt_seq_dict[x])\n",
    "#foldx_shifted = all_cyp_variants_rev['foldx_score'] - all_cyp_variants_rev['foldx_score'].min()\n",
    "#all_cyp_variants_rev['foldx_score'] = np.log1p(foldx_shifted)\n",
    "all_cyp_variants_rev = all_cyp_variants_rev[all_cyp_variants_rev['Gene'].isin(['CYP2D6'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e80be7-60d1-4bf7-b385-3e70095b6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_mutation_positions(mut_position_array):\n",
    "    \"\"\"numpy array에서 1.0인 위치들을 찾아서 반환\"\"\"\n",
    "    if hasattr(mut_position_array, '__iter__'):\n",
    "        try:\n",
    "            positions = [i+1 for i, val in enumerate(mut_position_array) if val == 1.0]\n",
    "            return positions\n",
    "        except:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def convert_single_missense_variants(df):\n",
    "    \"\"\"\n",
    "    기존 single missense의 variant 컬럼을 A35T 형태로 변환\n",
    "    \"\"\"\n",
    "    print(\"Converting single missense variants to A35T format...\")\n",
    "    \n",
    "    converted_df = df.copy()\n",
    "    converted_count = 0\n",
    "    \n",
    "    for idx, row in converted_df.iterrows():\n",
    "        if row['variant'] == 'missense' and row['status'] == 'Success':\n",
    "            # Position 추출\n",
    "            positions = extract_mutation_positions(row['mut_position'])\n",
    "            \n",
    "            if positions:\n",
    "                sequence = list(row['Sequence'])\n",
    "                wt_sequence = list(row['wt_seq']) \n",
    "                variant_descriptions = []\n",
    "                \n",
    "                for pos in positions:\n",
    "                    pos_idx = pos - 1  # 0-based indexing\n",
    "                    if 0 <= pos_idx < len(sequence) and pos_idx < len(wt_sequence):\n",
    "                        wt_aa = wt_sequence[pos_idx]\n",
    "                        mut_aa = sequence[pos_idx]\n",
    "                        variant_descriptions.append(f\"{wt_aa}{pos}{mut_aa}\")\n",
    "                \n",
    "                if variant_descriptions:\n",
    "                    variant_string = \", \".join(variant_descriptions)\n",
    "                    converted_df.at[idx, 'variant'] = variant_string\n",
    "                    converted_count += 1\n",
    "    \n",
    "    print(f\"Converted {converted_count} single missense variants\")\n",
    "    return converted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deff7026-ef7a-4a21-855b-74341e99ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting single missense variants to A35T format...\n",
      "Converted 1332 single missense variants\n"
     ]
    }
   ],
   "source": [
    "all_cyp_variants_rev = convert_single_missense_variants(all_cyp_variants_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1cd4bc-931d-4a98-ae81-4b8cbdb8935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>mut_position</th>\n",
       "      <th>variant</th>\n",
       "      <th>am_score</th>\n",
       "      <th>am_label</th>\n",
       "      <th>esm_score</th>\n",
       "      <th>conserv_score</th>\n",
       "      <th>foldx_score</th>\n",
       "      <th>status</th>\n",
       "      <th>mut_sum</th>\n",
       "      <th>esm1v_score</th>\n",
       "      <th>wt_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>wild_type</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>wild_type</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MRLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>G2R</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>-7.061</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.637347</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MVLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>G2V</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>-5.508</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.146168</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.716359</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MWLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>G2W</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>-7.153</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.092842</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.486700</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGQEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>L3Q</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>-4.553</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.424936</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.643526</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>V495M</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>-6.897</td>\n",
       "      <td>0.649</td>\n",
       "      <td>-0.409300</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.354896</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>P496S</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>BENIGN</td>\n",
       "      <td>-6.671</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.920530</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.539027</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>R497C</td>\n",
       "      <td>0.4641</td>\n",
       "      <td>AMBIGUOUS</td>\n",
       "      <td>-9.810</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.516240</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.398916</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>R497H</td>\n",
       "      <td>0.3970</td>\n",
       "      <td>AMBIGUOUS</td>\n",
       "      <td>-7.684</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.502170</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.000917</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>CYP2D6</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>R497P</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>PATHOGENIC</td>\n",
       "      <td>-12.483</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.423550</td>\n",
       "      <td>Success</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.501418</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1333 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gene                                           Sequence  \\\n",
       "6537  CYP2D6  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "6538  CYP2D6  MRLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "6539  CYP2D6  MVLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "6540  CYP2D6  MWLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "6541  CYP2D6  MGQEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "...      ...                                                ...   \n",
       "7865  CYP2D6  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "7866  CYP2D6  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "7867  CYP2D6  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "7868  CYP2D6  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "7869  CYP2D6  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "\n",
       "                                           mut_position variant  am_score  \\\n",
       "6537  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      WT    0.0000   \n",
       "6538  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     G2R    0.2136   \n",
       "6539  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     G2V    0.1502   \n",
       "6540  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     G2W    0.1895   \n",
       "6541  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     L3Q    0.0798   \n",
       "...                                                 ...     ...       ...   \n",
       "7865  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   V495M    0.1450   \n",
       "7866  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   P496S    0.1115   \n",
       "7867  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   R497C    0.4641   \n",
       "7868  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   R497H    0.3970   \n",
       "7869  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   R497P    0.7051   \n",
       "\n",
       "        am_label  esm_score  conserv_score  foldx_score     status  mut_sum  \\\n",
       "6537   wild_type      0.000          1.000     0.000000  wild_type      0.0   \n",
       "6538      BENIGN     -7.061          0.867     0.026774    Success      1.0   \n",
       "6539      BENIGN     -5.508          0.867     0.146168    Success      1.0   \n",
       "6540      BENIGN     -7.153          0.867     0.092842    Success      1.0   \n",
       "6541      BENIGN     -4.553          0.940     0.424936    Success      1.0   \n",
       "...          ...        ...            ...          ...        ...      ...   \n",
       "7865      BENIGN     -6.897          0.649    -0.409300    Success      1.0   \n",
       "7866      BENIGN     -6.671          0.669     1.920530    Success      1.0   \n",
       "7867   AMBIGUOUS     -9.810          1.000     2.516240    Success      1.0   \n",
       "7868   AMBIGUOUS     -7.684          1.000     3.502170    Success      1.0   \n",
       "7869  PATHOGENIC    -12.483          1.000     6.423550    Success      1.0   \n",
       "\n",
       "      esm1v_score                                             wt_seq  \n",
       "6537     0.000000  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "6538    -1.637347  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "6539    -0.716359  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "6540    -0.486700  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "6541    -2.643526  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "...           ...                                                ...  \n",
       "7865    -3.354896  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "7866    -3.539027  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "7867    -6.398916  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "7868    -6.000917  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "7869    -8.501418  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "\n",
       "[1333 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cyp_variants_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a80a9dd-f4cf-47f3-b54c-67bcfb8f69ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3232579/2604973910.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  wt_seq = item[2]\n",
      "/tmp/ipykernel_3232579/2604973910.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  vr_seq = item[1]\n",
      "/tmp/ipykernel_3232579/2604973910.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  vr_feat_dict[item[0]] = temp[0].detach().to('cpu').numpy()\n"
     ]
    }
   ],
   "source": [
    "all_vars = all_cyp_variants_rev[['variant', 'Sequence', 'wt_seq']].drop_duplicates()\n",
    "wt_texts = all_vars['wt_seq'].values\n",
    "vr_texts = all_vars['Sequence'].values\n",
    "#custom_collator = VarCollator()\n",
    "custom_collator = MultiTaskVarCollator()\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "model.eval()\n",
    "vr_feat_dict = {}\n",
    "set_seed(0)\n",
    "for index, item in all_vars.iterrows():\n",
    "    wt_seq = item[2]\n",
    "    vr_seq = item[1]\n",
    "    wt_inputs = tokenizer(wt_seq, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    vr_inputs = tokenizer(vr_seq, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        temp = model.am_feature(wt_inputs['input_ids'], wt_inputs['attention_mask'], vr_inputs['input_ids'], vr_inputs['attention_mask'])\n",
    "        #temp = model.am_feature(vr_inputs['input_ids'], vr_inputs['attention_mask'])\n",
    "        vr_feat_dict[item[0]] = temp[0].detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fe3af-1acc-4e0f-92e6-cbe7dcdc3300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vr_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af054ef8-bb8a-4211-a5ec-1ce5e108464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/CYP2D6_variant_ESM3_missense_250714.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vr_feat_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423489f9-aa20-4999-98c3-f566f740d913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Allele</th>\n",
       "      <th>Substrate</th>\n",
       "      <th>cl_rev</th>\n",
       "      <th>vmax_rev</th>\n",
       "      <th>km_rev</th>\n",
       "      <th>source</th>\n",
       "      <th>avg_cl_rev</th>\n",
       "      <th>cl</th>\n",
       "      <th>wt_seqs</th>\n",
       "      <th>vr_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*1</td>\n",
       "      <td>Amitriptyline</td>\n",
       "      <td>0.322035</td>\n",
       "      <td>3.37200</td>\n",
       "      <td>10.9000</td>\n",
       "      <td>KIT</td>\n",
       "      <td>0.322035</td>\n",
       "      <td>-1.133096</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*1</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>0.082551</td>\n",
       "      <td>2.59250</td>\n",
       "      <td>31.4050</td>\n",
       "      <td>KIST</td>\n",
       "      <td>0.082551</td>\n",
       "      <td>-2.494344</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*1</td>\n",
       "      <td>Atomoxetine</td>\n",
       "      <td>6.303000</td>\n",
       "      <td>55.31000</td>\n",
       "      <td>8.7750</td>\n",
       "      <td>KIT</td>\n",
       "      <td>6.303000</td>\n",
       "      <td>1.841026</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*1</td>\n",
       "      <td>Carvedilol</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>3.21500</td>\n",
       "      <td>12.1700</td>\n",
       "      <td>KIT</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>-1.331049</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*1</td>\n",
       "      <td>Chlorpromazine</td>\n",
       "      <td>4.311000</td>\n",
       "      <td>41.24000</td>\n",
       "      <td>9.5670</td>\n",
       "      <td>KIT</td>\n",
       "      <td>4.311000</td>\n",
       "      <td>1.461170</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>*9</td>\n",
       "      <td>Sertraline</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.20840</td>\n",
       "      <td>1.2680</td>\n",
       "      <td>KIT</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>-1.807889</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>*9</td>\n",
       "      <td>Tamoxifen</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KIT</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>-2.840439</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>*9</td>\n",
       "      <td>Thioridazine</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.04493</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>KIT</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>-3.057608</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>*9</td>\n",
       "      <td>Tolterodine</td>\n",
       "      <td>1.709041</td>\n",
       "      <td>1.87770</td>\n",
       "      <td>1.0987</td>\n",
       "      <td>KIST</td>\n",
       "      <td>1.709041</td>\n",
       "      <td>0.535933</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>*9</td>\n",
       "      <td>Venlafaxine</td>\n",
       "      <td>0.173267</td>\n",
       "      <td>1.79860</td>\n",
       "      <td>10.3803</td>\n",
       "      <td>KIST</td>\n",
       "      <td>0.173267</td>\n",
       "      <td>-1.752923</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "      <td>MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Allele       Substrate    cl_rev  vmax_rev   km_rev source  avg_cl_rev  \\\n",
       "0       *1   Amitriptyline  0.322035   3.37200  10.9000    KIT    0.322035   \n",
       "1       *1    Aripiprazole  0.082551   2.59250  31.4050   KIST    0.082551   \n",
       "2       *1     Atomoxetine  6.303000  55.31000   8.7750    KIT    6.303000   \n",
       "3       *1      Carvedilol  0.264200   3.21500  12.1700    KIT    0.264200   \n",
       "4       *1  Chlorpromazine  4.311000  41.24000   9.5670    KIT    4.311000   \n",
       "..     ...             ...       ...       ...      ...    ...         ...   \n",
       "286     *9      Sertraline  0.164000   0.20840   1.2680    KIT    0.164000   \n",
       "287     *9       Tamoxifen  0.058400       NaN      NaN    KIT    0.058400   \n",
       "288     *9    Thioridazine  0.047000   0.04493   0.9567    KIT    0.047000   \n",
       "289     *9     Tolterodine  1.709041   1.87770   1.0987   KIST    1.709041   \n",
       "290     *9     Venlafaxine  0.173267   1.79860  10.3803   KIST    0.173267   \n",
       "\n",
       "           cl                                            wt_seqs  \\\n",
       "0   -1.133096  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "1   -2.494344  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "2    1.841026  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "3   -1.331049  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "4    1.461170  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "..        ...                                                ...   \n",
       "286 -1.807889  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "287 -2.840439  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "288 -3.057608  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "289  0.535933  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "290 -1.752923  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...   \n",
       "\n",
       "                                               vr_seqs  \n",
       "0    MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "1    MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "2    MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "3    MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "4    MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "..                                                 ...  \n",
       "286  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "287  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "288  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "289  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "290  MGLEALVPLAVIVAIFLLLVDLMHRRQRWAARYPPGPLPLPGLGNL...  \n",
       "\n",
       "[291 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cyp2d6 = pd.read_csv(\"data/cyp2d6_final_ours_preprocessed_250407.csv\")\n",
    "cyp2d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d482a72-8aaf-4ec6-b5fb-337e6fa02180",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = cyp2d6[['Allele', 'vr_seqs', 'wt_seqs']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4828439-8591-48cc-952b-a716c22f6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_texts = all_vars['wt_seqs'].values\n",
    "vr_texts = all_vars['vr_seqs'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b88b8f-0413-458b-9ab1-2c67f225fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_collator = VarCollator()\n",
    "custom_collator = MultiTaskVarCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e8aaee2-8af8-486e-8a8a-d897b0478334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Amitriptyline', 'Aripiprazole', 'Atomoxetine', 'Carvedilol',\n",
       "       'Chlorpromazine', 'Clomipramine', 'Clozapine', 'Dextromethorphan',\n",
       "       'Doxepin', 'Dronedarone', 'Duloxetine', 'Fluoxetine', 'Gefitinib',\n",
       "       'Imipramine', 'Meclizine', 'Mexiletine', 'Mirtazapine',\n",
       "       'Nefazodone', 'Nortriptyline', 'Olanzapine', 'Ondansetron',\n",
       "       'Paroxetine', 'Perhexiline', 'Perphenazine', 'Pimozide',\n",
       "       'Primaquine', 'Promethazine', 'Propafenone', 'Ranolazine',\n",
       "       'Ritonavir', 'Sertraline', 'Tamoxifen', 'Thioridazine',\n",
       "       'Tolterodine', 'Venlafaxine'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyp2d6['Substrate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b10b119-369a-4dde-8e86-6316092fe838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3232579/864922504.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  wt_seq = item[2]\n",
      "/tmp/ipykernel_3232579/864922504.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  vr_seq = item[1]\n",
      "/tmp/ipykernel_3232579/864922504.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  vr_feat_dict[item[0]] = temp[0].detach().to('cpu').numpy()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model.eval()\n",
    "vr_feat_dict = {}\n",
    "set_seed(0)\n",
    "for index, item in all_vars.iterrows():\n",
    "    wt_seq = item[2]\n",
    "    vr_seq = item[1]\n",
    "    wt_inputs = tokenizer(wt_seq, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    vr_inputs = tokenizer(vr_seq, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        temp = model.am_feature(wt_inputs['input_ids'], wt_inputs['attention_mask'], vr_inputs['input_ids'], vr_inputs['attention_mask'])\n",
    "        #temp = model.am_feature(vr_inputs['input_ids'], vr_inputs['attention_mask'])\n",
    "        vr_feat_dict[item[0]] = temp[0].detach().to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80930190-9183-4e62-b4bc-0112663119ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46b4c2-eb4e-406f-b851-90c69a3d6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/CYP2D6_MT_KIT_ESM3_250624.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vr_feat_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e342dcd-9c7a-46c9-8912-029c91c1a3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a220e35-1d59-454f-9b4e-dad3e0b44aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "\n",
    "sys.path.append(\"./src/molebert\")\n",
    "from model import GNN, GNN_graphpred\n",
    "from loader import mol_to_graph_data_obj_simple, allowable_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfba6048-a21b-4172-8486-a8d4533d08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from src.utils.training_utils import set_seed\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b351b-28dc-4a52-a82e-33d269e66380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0aaae35-1f77-416c-8e01-a0b415b42898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform = None, pre_transform = None, pre_filter = None, empty=False, force_reload=True):\n",
    "        self.data_path = root\n",
    "        super(GraphDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.transform, self.pre_transform, self.pre_filter = transform, pre_transform, pre_filter\n",
    "        if not empty:\n",
    "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    def get(self,idx):\n",
    "        data = Data()\n",
    "        for key in self.data.keys():\n",
    "            item, slices = self.data[key], self.slices[key]\n",
    "            s = list(repeat(slice(None), item.dim()))\n",
    "            s[data.__cat_dim__(key, item)] = slice(slices[idx], slices[idx + 1])\n",
    "            data[key] = item[s]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        file_name_list = os.listdir(self.raw_dir)\n",
    "        return file_name_list\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'geometric_data_processed.pt'\n",
    "    def download(self):\n",
    "        raise NotImplementedError('Must indicate valid location of raw data. No download allowed')\n",
    "    \n",
    "    def process(self):\n",
    "        # 원본 데이터 로드\n",
    "        input_df = pd.read_csv(f'{self.data_path}/raw/sub2smi.csv')\n",
    "        smiles_list = input_df['SMILES'].tolist()\n",
    "        rdkit_mol_objs = [AllChem.MolFromSmiles(s) for s in smiles_list]\n",
    "        data_list = []\n",
    "        data_smiles_list = []\n",
    "\n",
    "        for i in range(len(smiles_list)):\n",
    "            rdkit_mol = rdkit_mol_objs[i]\n",
    "            data = mol_to_graph_data_obj_simple(rdkit_mol)\n",
    "            data_list.append(data)\n",
    "            data_smiles_list.append(smiles_list[i])\n",
    "\n",
    "        # 데이터 및 슬라이스 저장\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1516269b-5b2d-4bf3-921b-c0f9611f7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "molebert_model = GNN_graphpred(num_layer=5, emb_dim=300, num_tasks=5, JK='last', drop_ratio=0.1, graph_pooling='mean',gnn_type='gin')\n",
    "\n",
    "molebert_model.from_pretrained('./src/molebert/model_gin/Mole-BERT.pth')\n",
    "device = \"cuda\"\n",
    "molebert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7571612-112f-4ef3-a853-9ed1aff090e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdataset = GraphDataset('./src/molebert/dataset/cyp_ours_subs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5dc44-452f-4811-b740-eacf55a5d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loader = DataLoader(gdataset, batch_size = 1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a7726-a38f-4995-a758-c4cce667df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "molebert_model.to(device)\n",
    "drug2smi = pd.read_csv(\"./src/molebert/dataset/cyp_ours_subs/raw/sub2smi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7a799-348c-409e-bad3-258e9eec2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "mol_arr_dict = {}\n",
    "i = 0\n",
    "molebert_model.eval()\n",
    "set_seed(0)\n",
    "for g in g_loader:\n",
    "    g.to(device)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        node_rep = molebert_model.gnn(g['x'], g['edge_index'], g['edge_attr'])\n",
    "        d_name = drug2smi.iloc[i, :]['Substrate']\n",
    "        mol_arr_dict[d_name] = node_rep.detach().to('cpu').numpy()\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af48e87-47be-40e5-9244-432ee65771f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/MoleBERT_Substrate_NoPreMoleBERT_KIT_0624.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mol_arr_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6abb9e-df3c-41af-b0e9-76654854c241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_cyp",
   "language": "python",
   "name": "deep_cyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
