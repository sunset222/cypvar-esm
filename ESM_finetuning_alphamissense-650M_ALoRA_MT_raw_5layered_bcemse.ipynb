{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa632ddd-0e6c-4a64-aa13-28c37b492de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.utils.training_utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ce6805-5b68-46b7-a1d0-7a83b4898d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61352dda-cd21-4c8c-b156-a31a806b22ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  4 09:30:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:65:00.0 Off |                  Off |\n",
      "| 74%   33C    P8             16W /  450W |    1083MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    On  |   00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   49C    P0             99W /  350W |    3888MiB /  46068MiB |     16%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2635381      C   ...miniconda3/envs/deep_cyp/bin/python        384MiB |\n",
      "|    0   N/A  N/A   4050125      C   ...miniconda3/envs/deep_cyp/bin/python        684MiB |\n",
      "|    1   N/A  N/A   3582841      C   ...miniconda3/envs/deep_cyp/bin/python        724MiB |\n",
      "|    1   N/A  N/A   3603275      C   ...miniconda3/envs/deep_cyp/bin/python        766MiB |\n",
      "|    1   N/A  N/A   4009804      C   ...miniconda3/envs/deep_cyp/bin/python        920MiB |\n",
      "|    1   N/A  N/A   4082334      C   ...miniconda3/envs/deep_cyp/bin/python        730MiB |\n",
      "|    1   N/A  N/A   4137814      C   ...miniconda3/envs/deep_cyp/bin/python        718MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b519d6a6-2616-4526-8880-6bd703276dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.esmfinetune_3labels import MultiTaskVarDataset, MultiTaskVarCollator\n",
    "from src.varmodel_MT_AllLoRA_ESM3_proj import CYPVarAM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99773e1c-c515-4307-a1cd-17ee5e69548a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebeecd-af85-49bc-92a5-01fbc9abd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "esm_model = AutoModelForMaskedLM.from_pretrained('Synthyra/ESMplusplus_small', trust_remote_code=True)\n",
    "tokenizer = esm_model.tokenizer\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "# esm_model = EsmModel.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9e6fc-e25f-48b7-9d1a-e0db37ba3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe730234-d1ba-445c-8fcb-54d579a713f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "intermed_list = []\n",
    "for i in range(30):\n",
    "    if i > 24:\n",
    "        intermed_list.append(str(i)+\".attn.layernorm_qkv.1\")\n",
    "        intermed_list.append(str(i)+\".attn.out_proj\")\n",
    "        intermed_list.append(str(i)+\".ffn.1\")\n",
    "        intermed_list.append(str(i)+\".ffn.3\")\n",
    "       \n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    bias=\"none\",\n",
    "    #use_dora=True,\n",
    "    target_modules=intermed_list#[\"layernorm_qkv.1\", \"out_proj\", \"ffn.1\", \"ffn.3\"]#\"query\", \"key\", \"value\", \"dense\"] + intermed_list\n",
    ")\n",
    "lora_esm_model = get_peft_model(esm_model, config)\n",
    "\n",
    "# for param in esm_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "model = CYPVarAM(esm_model = lora_esm_model, drop_att = 0.1, drop_pff = 0.1,  input_size = 960, hidden_size = 300, num_heads = 6, num_tasks = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e030453-bf51-4d9c-8952-543b39f36ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bddd8e-5140-4128-b10a-ef96cfe4aa8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad90a127-f6fe-4b95-98a2-0400ca018c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/uniprot_cyp_variant_protvar_250709.pkl\", \"rb\") as f:\n",
    "    all_cyp_variants_rev = pickle.load(f)\n",
    "wt_seq_dict = all_cyp_variants_rev[all_cyp_variants_rev['variant']=='WT'][['Gene', 'Sequence']].set_index('Gene').to_dict()['Sequence']\n",
    "all_cyp_variants_rev['wt_seq'] = all_cyp_variants_rev['Gene'].map(lambda x: wt_seq_dict[x])\n",
    "#foldx_shifted = all_cyp_variants_rev['foldx_score'] - all_cyp_variants_rev['foldx_score'].min()\n",
    "#all_cyp_variants_rev['foldx_score'] = np.log1p(foldx_shifted)\n",
    "#all_cyp_variants_rev = all_cyp_variants_rev[all_cyp_variants_rev['Gene'].isin(['CYP2D6'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330e890d-637a-468d-b730-69051127cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34662"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cyp_variants_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3005df-4129-4915-93d3-6382159a49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Applies min-max normalization to a specific column in a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the column to normalize\n",
    "    column_name (str): The name of the column to normalize\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with the normalized column\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Extract min and max values from the column\n",
    "    mean_val = df[column_name].mean()\n",
    "    std_val = df[column_name].std()\n",
    "    \n",
    "    \n",
    "    df_normalized[column_name+'_std'] = (df[column_name] - mean_val) / (std_val + 1e-8)\n",
    "    \n",
    "    return df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Applies min-max normalization to a specific column in a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the column to normalize\n",
    "    column_name (str): The name of the column to normalize\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with the normalized column\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Extract min and max values from the column\n",
    "    min_val = df[column_name].min()\n",
    "    max_val = df[column_name].max()\n",
    "    \n",
    "    # Check if min and max are the same to avoid division by zero\n",
    "    if min_val == max_val:\n",
    "        df_normalized[column_name] = 0  # If all values are the same, normalize to 0\n",
    "    else:\n",
    "        # Apply min-max normalization formula: (x - min) / (max - min)\n",
    "        df_normalized[column_name+'_minmax'] = (df[column_name] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61903505-b00a-4d88-b0fd-7d86608b6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(\n",
    "    all_cyp_variants_rev,  test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8656e69f-24d7-419e-b320-88e5361cd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wt_texts = train_df['wt_seq'].values\n",
    "train_vr_texts = train_df['Sequence'].values\n",
    "\n",
    "val_wt_texts = val_df['wt_seq'].values\n",
    "val_vr_texts = val_df['Sequence'].values\n",
    "\n",
    "train_labels_1 = (train_df[['am_score']]).astype('float32').values\n",
    "train_labels_2 = (train_df[['esm1v_score']]).astype('float32').values\n",
    "train_labels_3 = (train_df[['foldx_score']]).astype('float32').values\n",
    "#train_labels_4 = (train_df[['conserv_score_std']]).astype('float32').values\n",
    "val_labels_1 = (val_df[['am_score']]).astype('float32').values\n",
    "val_labels_2 = (val_df[['esm1v_score']]).astype('float32').values\n",
    "val_labels_3 = (val_df[['foldx_score']]).astype('float32').values\n",
    "#val_labels_4 = (val_df[['conserv_score_std']]).astype('float32').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57d11a-dc2b-45b3-a62b-bbaa2cdb6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004aef3-81dc-4f2c-b4dd-5f88d3acde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942a199-c441-49e7-b556-3118365e0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings1 = tokenizer(list(train_wt_texts), padding=True)\n",
    "train_encodings2 = tokenizer(list(train_vr_texts), padding=True)\n",
    "\n",
    "val_encodings1 = tokenizer(list(val_wt_texts), padding=True)\n",
    "val_encodings2 = tokenizer(list(val_vr_texts), padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e96957-e820-4935-9f85-0d78ea151556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiTaskVarDataset(train_encodings1, train_encodings2, train_labels_1, train_labels_2, train_labels_3)\n",
    "val_dataset = MultiTaskVarDataset(val_encodings1, val_encodings2, val_labels_1, val_labels_2, val_labels_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0bcaae-f093-4583-b23f-58c0b2e6dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_collator = MultiTaskVarCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b94f85-3010-4645-a389-a48d40810fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.esmfinetune_3labels import eval_multitask_reg_metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    result = eval_multitask_reg_metrics(\n",
    "        predictions=predictions, \n",
    "        labels=labels)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75dc86-834a-40a2-a9a3-c7b1a7c95e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\", \"Trainable\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        params = parameter.numel()\n",
    "        #print(name, params, parameter.requires_grad)\n",
    "        table.add_row([name, params, parameter.requires_grad])\n",
    "        if parameter.requires_grad:\n",
    "            total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab126b-fe5f-49e0-a36c-18fcf45a9a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdef73d-06f3-45a2-b92a-9168ccfe55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "def create_optimizer(model, training_args):\n",
    "    # Parameter 그룹 분리\n",
    "    lora_params = []\n",
    "    cross_attn_params = []\n",
    "    predict_params = []\n",
    "    other_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "            \n",
    "        if 'lora_' in name:  # DoRA parameters\n",
    "            lora_params.append(param)\n",
    "        else:  # Other trainable parameters\n",
    "            other_params.append(param)\n",
    "    \n",
    "    # Optimizer with different learning rates\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': lora_params, 'lr': 2e-5},       # LoRA: 더 낮게\n",
    "        {'params': other_params, 'lr': 1e-4}       # Others: 기본값\n",
    "    ], weight_decay=0.0)\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "# TrainingArguments (거의 동일)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"esm3_MT_small_raw_5layer\",\n",
    "    # learning_rate=2e-5,  # 주석 처리 (custom optimizer 사용)\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=20,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", \n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=1,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    metric_for_best_model=\"eval_r2_avg\",\n",
    "    label_names=['labels'],\n",
    "    dataloader_drop_last=True,\n",
    "    lr_scheduler_type='cosine'\n",
    ")\n",
    "\n",
    "# Trainer with custom optimizer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=custom_collator,\n",
    "    optimizers=(create_optimizer(model, training_args), None)  # (optimizer, scheduler)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8155a7-0555-49f4-8ade-6710dbcbb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f02f5-f494-4505-b835-eef1effe4bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_cyp",
   "language": "python",
   "name": "deep_cyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
